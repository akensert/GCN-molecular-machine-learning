{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "from gcn import datasets as gcn_datasets\n",
    "from gcn import models as gcn_models\n",
    "\n",
    "from rgcn import datasets as rgcn_datasets\n",
    "from rgcn import models as rgcn_models\n",
    "\n",
    "from utils import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define (random) hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters = {\n",
    "    'num_bases':        lambda:       np.random.choice([-1, 2, 4]),\n",
    "    'num_gconv_layers': lambda:       np.random.randint(*[3, 5+1]),\n",
    "    'num_gconv_units':  lambda:       np.random.randint(*[128, 256+1]),\n",
    "    'learning_rate':    lambda:       np.random.uniform(*[1e-4, 1e-3]),\n",
    "    'num_epochs':       lambda:       np.random.randint(*[100, 300+1]),\n",
    "    'batch_size':       lambda:       np.random.choice([32, 64, 128]),\n",
    "    'weight_decay':     lambda:   10**np.random.uniform(*[-6, -3]),\n",
    "    'num_dense_layers': lambda:       np.random.randint(*[1, 2+1]),\n",
    "    'num_dense_units':  lambda:       np.random.randint(*[256, 1024]),\n",
    "    'dense_dropout':    lambda:       np.random.uniform(*[0.0, 0.3]),\n",
    "}\n",
    "\n",
    "\n",
    "dataset_names = ['SMRT', 'RIKEN', 'Fiehn_HILIC', 'SMRT']\n",
    "\n",
    "NUM_SEARCHES = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to generate prediction files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_output(model_obj, model_params, model_weights, \n",
    "                    dataset_obj, save_path):\n",
    "    \n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    print(model_params)\n",
    "    \n",
    "    files = glob.glob(f'../input/tfrecords/{save_path.split(\"/\")[-3]}/*')\n",
    "\n",
    "    for file in files:\n",
    "        \n",
    "        dataset = dataset_obj(file, batch_size=128, training=False)\n",
    "        model = model_obj(**model_params)\n",
    "        \n",
    "        dummy_data = next(iter(dataset.get_iterator()))\n",
    "        model([dummy_data['adjacency_matrix'], dummy_data['feature_matrix']])\n",
    "        model.set_weights(model_weights)\n",
    "        \n",
    "        trues, preds = model.predict(dataset.get_iterator())\n",
    "        #latent = model.get_latent_spaces(dataset.get_iterator())\n",
    "        \n",
    "        path = save_path + file.split('/')[-1].split('.')[0] # + \"_1\"\n",
    "        np.save(path, np.stack([trues, preds]))\n",
    "        #np.save(path + '_latent', latent)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ea1fc387134c35a30cb5575345779c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dataset_name in dataset_names:\n",
    "\n",
    "    best_error = float('inf')\n",
    "    \n",
    "    for i in tqdm(range(NUM_SEARCHES)):\n",
    "\n",
    "        np.random.seed(42+i)\n",
    "\n",
    "        num_gconv_layers = parameters['num_gconv_layers']()\n",
    "        num_gconv_units = parameters['num_gconv_units']()\n",
    "        learning_rate = parameters['learning_rate']()\n",
    "        batch_size = parameters['batch_size']()\n",
    "        num_epochs = parameters['num_epochs']()\n",
    "        weight_decay = parameters['weight_decay']()\n",
    "        num_dense_layers = parameters['num_dense_layers']()\n",
    "        num_dense_units = parameters['num_dense_units']()\n",
    "        dense_dropout = parameters['dense_dropout']()\n",
    "        \n",
    "        params = {\n",
    "            \"gconv_units\": [num_gconv_units] * num_gconv_layers,\n",
    "            \"gconv_regularizer\": tf.keras.regularizers.L2(weight_decay),\n",
    "            \"initial_learning_rate\": learning_rate,\n",
    "            'dense_units': [num_dense_units] * num_dense_layers,\n",
    "            'dense_dropout': dense_dropout,\n",
    "        }\n",
    "        \n",
    "        if dataset_name == \"RIKEN\" or dataset_name == \"Fiehn_HILIC\":\n",
    "            train_dataset = gcn_datasets.GCNDataset(\n",
    "                f'../input/tfrecords/{dataset_name}/train.tfrec', batch_size, True)\n",
    "            valid_dataset = gcn_datasets.GCNDataset(\n",
    "                f'../input/tfrecords/{dataset_name}/valid.tfrec', batch_size, False)\n",
    "            test_1_dataset = gcn_datasets.GCNDataset(\n",
    "                f'../input/tfrecords/{dataset_name}/test_1.tfrec', batch_size, False)\n",
    "            test_2_dataset = gcn_datasets.GCNDataset(\n",
    "                f'../input/tfrecords/{dataset_name}/test_2.tfrec', batch_size, False)\n",
    "            additional_datasets={\n",
    "                'valid': valid_dataset.get_iterator(),\n",
    "                'test_1': test_1_dataset.get_iterator(),\n",
    "                'test_2': test_2_dataset.get_iterator(),\n",
    "            }\n",
    "        else:\n",
    "            train_dataset = gcn_datasets.GCNDataset(\n",
    "                f'../input/tfrecords/{dataset_name}/train.tfrec', batch_size, True)\n",
    "            valid_dataset = gcn_datasets.GCNDataset(\n",
    "                f'../input/tfrecords/{dataset_name}/valid.tfrec', batch_size, False)\n",
    "            test_1_dataset = gcn_datasets.GCNDataset(\n",
    "                f'../input/tfrecords/{dataset_name}/test_1.tfrec', batch_size, False)\n",
    "            additional_datasets={\n",
    "                'valid': valid_dataset.get_iterator(),\n",
    "                'test': test_1_dataset.get_iterator(),\n",
    "            }\n",
    "            \n",
    "        \n",
    "        model = gcn_models.GCNModel(**params)\n",
    "        model.fit(\n",
    "            train_dataset.get_iterator(), \n",
    "            additional_datasets=additional_datasets,\n",
    "            epochs=num_epochs, verbose=0\n",
    "        )\n",
    "        \n",
    "        if not os.path.isdir(f'../output/learning_curves/{dataset_name}/gcn/'):\n",
    "            os.makedirs(f'../output/learning_curves/{dataset_name}/gcn/')\n",
    "            \n",
    "        for k, v in model.learning_curves.items():\n",
    "            np.save(f'../output/learning_curves/{dataset_name}/gcn/{k}_{i}.npy', \n",
    "                    np.array(list(v)))\n",
    "            \n",
    "     \n",
    "        trues, preds = model.predict(valid_dataset.get_iterator())\n",
    "\n",
    "        error = metrics.get('mae')(trues, preds)\n",
    "        print(f'MAE                       : {error}\\n')\n",
    "        if dataset_name != 'SMRT':\n",
    "            print(f'test 1 = {model.learning_curves[\"test_1_mae\"][-1]}')\n",
    "            print(f'test 1 = {model.learning_curves[\"test_1_r2\"][-1]}')\n",
    "            print(f'test 2 = {model.learning_curves[\"test_2_mae\"][-1]}')\n",
    "            print(f'test 2 = {model.learning_curves[\"test_2_r2\"][-1]}')\n",
    "        else:\n",
    "            print(f'test = {model.learning_curves[\"test_mae\"][-1]}')\n",
    "            print(f'test = {model.learning_curves[\"test_r2\"][-1]}')\n",
    "        \n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            best_params = params.copy()\n",
    "            best_weights = model.get_weights()\n",
    "            \n",
    "            for k, v in model.learning_curves.items():\n",
    "                np.save(f'../output/learning_curves/{dataset_name}/gcn/{k}_best.npy', \n",
    "                        np.array(list(v)))\n",
    "\n",
    "    generate_output(\n",
    "        model_obj=gcn_models.GCNModel,\n",
    "        model_params=best_params,\n",
    "        model_weights=best_weights,\n",
    "        dataset_obj=gcn_datasets.GCNDataset,\n",
    "        save_path=f'../output/predictions/{dataset_name}/gcn/'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0, 2, 4, 8, 9, 10, 17, ..., ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631bd4e43661463db469cf5532836637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-c61280029467>\", line 57, in <module>\n",
      "    model.fit(\n",
      "  File \"/home/alex/Projects/research/finished/GCN-molecular-machine-learning/notebooks/../src/base_classes/models.py\", line 89, in fit\n",
      "    result = self._train_step(batch)\n",
      "  File \"/home/alex/Projects/research/finished/GCN-molecular-machine-learning/notebooks/../src/base_classes/models.py\", line 48, in _train_step\n",
      "    loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1477, in losses\n",
      "    loss_tensor = regularizer()\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1553, in _tag_callable\n",
      "    loss = loss()\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 2500, in _loss_for_variable\n",
      "    regularization = regularizer(v)\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/keras/regularizers.py\", line 322, in __call__\n",
      "    return self.l2 * math_ops.reduce_sum(math_ops.square(x))\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 10161, in square\n",
      "    return square_eager_fallback(\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 10196, in square_eager_fallback\n",
      "    _attr_T, (x,) = _execute.args_to_matching_eager([x], ctx, [_dtypes.bfloat16, _dtypes.half, _dtypes.float32, _dtypes.float64, _dtypes.int8, _dtypes.int16, _dtypes.int32, _dtypes.int64, _dtypes.complex64, _dtypes.complex128, ])\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 265, in args_to_matching_eager\n",
      "    tensor = ops.convert_to_tensor(t, ctx=ctx)\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 1540, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1992, in _dense_var_to_tensor\n",
      "    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1393, in _dense_var_to_tensor\n",
      "    return self.value()\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 565, in value\n",
      "    return self._read_variable_op()\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 672, in _read_variable_op\n",
      "    result = read_and_set_handle()\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 662, in read_and_set_handle\n",
      "    result = gen_resource_variable_ops.read_variable_op(\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 470, in read_variable_op\n",
      "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/alex/Envs/dl/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.8/posixpath.py\", line 424, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/usr/lib/python3.8/posixpath.py\", line 82, in join\n",
      "    for b in map(os.fspath, p):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c61280029467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgcn_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRGCNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         model.fit(\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/research/finished/GCN-molecular-machine-learning/notebooks/../src/base_classes/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_dataset, additional_datasets, epochs, steps_per_epoch, verbose)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/research/finished/GCN-molecular-machine-learning/notebooks/../src/base_classes/models.py\u001b[0m in \u001b[0;36m_train_step\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_losses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mlosses\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1476\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_losses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m         \u001b[0mloss_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_tag_callable\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_loss_for_variable\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m   2499\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/Regularizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2500\u001b[0;31m         \u001b[0mregularization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2501\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/keras/regularizers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msquare\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m  10160\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10161\u001b[0;31m       return square_eager_fallback(\n\u001b[0m\u001b[1;32m  10162\u001b[0m           x, name=name, ctx=_ctx)\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msquare_eager_fallback\u001b[0;34m(x, name, ctx)\u001b[0m\n\u001b[1;32m  10195\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msquare_eager_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10196\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10197\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallowed_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;31m# If we did not match an allowed dtype, try again with the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1392\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[0;34m()\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0m\u001b[1;32m    663\u001b[0m           self._handle, self._dtype)\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    471\u001b[0m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             )\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1193\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/dl/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_names:\n",
    "\n",
    "    best_error = float('inf')\n",
    "    \n",
    "    for i in tqdm(range(NUM_SEARCHES)):\n",
    "\n",
    "        np.random.seed(42+i)\n",
    "        \n",
    "        num_bases = parameters['num_bases']()\n",
    "        num_gconv_layers = parameters['num_gconv_layers']()\n",
    "        num_gconv_units = parameters['num_gconv_units']()\n",
    "        learning_rate = parameters['learning_rate']()\n",
    "        batch_size = parameters['batch_size']()\n",
    "        num_epochs = parameters['num_epochs']()\n",
    "        weight_decay = parameters['weight_decay']()\n",
    "        num_dense_layers = parameters['num_dense_layers']()\n",
    "        num_dense_units = parameters['num_dense_units']()\n",
    "        dense_dropout = parameters['dense_dropout']()\n",
    "        \n",
    "        #if i not in [0, 2, 4, 8, 9, 10, 17, 18]:\n",
    "        #    continue\n",
    "        \n",
    "        params = {\n",
    "           # \"gconv_num_bases\": num_bases,\n",
    "            \"gconv_units\": [num_gconv_units] * num_gconv_layers,\n",
    "            \"gconv_regularizer\": tf.keras.regularizers.L2(weight_decay),\n",
    "            \"initial_learning_rate\": learning_rate,\n",
    "            'dense_units': [num_dense_units] * num_dense_layers,\n",
    "            'dense_dropout': dense_dropout,\n",
    "        }\n",
    "\n",
    "        train_dataset = rgcn_datasets.RGCNDataset(\n",
    "            f'../input/tfrecords/{dataset_name}/train.tfrec', batch_size, True)\n",
    "        valid_dataset = rgcn_datasets.RGCNDataset(\n",
    "            f'../input/tfrecords/{dataset_name}/valid.tfrec', batch_size, False)\n",
    "        \n",
    "        if dataset_name == \"RIKEN\" or dataset_name == \"Fiehn_HILIC\":\n",
    "            test_1_dataset = rgcn_datasets.RGCNDataset(\n",
    "                f'../input/tfrecords/{dataset_name}/test_1.tfrec', batch_size, False)\n",
    "            test_2_dataset = rgcn_datasets.RGCNDataset(\n",
    "                f'../input/tfrecords/{dataset_name}/test_2.tfrec', batch_size, False)\n",
    "            additional_datasets={\n",
    "                'valid': valid_dataset.get_iterator(),\n",
    "                'test_1': test_1_dataset.get_iterator(),\n",
    "                'test_2': test_2_dataset.get_iterator(),\n",
    "            }\n",
    "        else:\n",
    "            test_1_dataset = rgcn_datasets.RGCNDataset(\n",
    "                f'../input/tfrecords/{dataset_name}/test.tfrec', batch_size, False)\n",
    "            additional_datasets={\n",
    "                'valid': valid_dataset.get_iterator(),\n",
    "                'test': test_1_dataset.get_iterator(),\n",
    "            }\n",
    "            \n",
    "\n",
    "        model = rgcn_models.RGCNModel(**params)\n",
    "        model.fit(\n",
    "            train_dataset.get_iterator(), \n",
    "            additional_datasets=additional_datasets,\n",
    "            epochs=num_epochs, verbose=0\n",
    "        )\n",
    "        \n",
    "        if not os.path.isdir(f'../output/learning_curves/{dataset_name}/rgcn/'):\n",
    "            os.makedirs(f'../output/learning_curves/{dataset_name}/rgcn/')\n",
    "                \n",
    "        for k, v in model.learning_curves.items():\n",
    "            np.save(f'../output/learning_curves/{dataset_name}/rgcn/{k}_{i}.npy', \n",
    "                    np.array(list(v)))\n",
    "            \n",
    "     \n",
    "        trues, preds = model.predict(valid_dataset.get_iterator(), verbose=0)\n",
    "\n",
    "        error = metrics.get('mae')(trues, preds)\n",
    "        print(f'MAE                       : {error}\\n')\n",
    "        if dataset_name != 'SMRT':\n",
    "            print(f'test 1 = {model.learning_curves[\"test_1_mae\"][-1]}')\n",
    "            print(f'test 1 = {model.learning_curves[\"test_1_r2\"][-1]}')\n",
    "            print(f'test 2 = {model.learning_curves[\"test_2_mae\"][-1]}')\n",
    "            print(f'test 2 = {model.learning_curves[\"test_2_r2\"][-1]}')\n",
    "        else:\n",
    "            print(f'test = {model.learning_curves[\"test_mae\"][-1]}')\n",
    "            print(f'test = {model.learning_curves[\"test_r2\"][-1]}')\n",
    "        \n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            best_params = params.copy()\n",
    "            best_weights = model.get_weights()\n",
    "            \n",
    "            for k, v in model.learning_curves.items():\n",
    "                np.save(f'../output/learning_curves/{dataset_name}/rgcn/{k}_best.npy', \n",
    "                        np.array(list(v)))\n",
    "\n",
    "\n",
    "    generate_output(\n",
    "        model_obj=rgcn_models.RGCNModel,\n",
    "        model_params=best_params,\n",
    "        model_weights=best_weights,\n",
    "        dataset_obj=rgcn_datasets.RGCNDataset,\n",
    "        save_path=f'../output/predictions/{dataset_name}/rgcn/'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
