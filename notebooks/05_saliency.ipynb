{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import multiprocessing \n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Lipinski\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import DataStructs\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from ops import transform_ops\n",
    "from gcn.datasets import GCNDataset\n",
    "from gcn.models import GCNModel\n",
    "from gcn import saliency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define function for serving trained model later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serve_model(model):\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        [tf.TensorSpec([None, None], dtype='float32', name='A'),\n",
    "         tf.TensorSpec([None, None], dtype='float32', name='H')]\n",
    "    ])\n",
    "    def serve(inputs):\n",
    "        return {\n",
    "            'prediction': model.call(\n",
    "                inputs=[inputs[0][tf.newaxis], inputs[1][tf.newaxis]],\n",
    "                training=False\n",
    "            )\n",
    "        }\n",
    "    return serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train on Fiehn HILIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "\n",
    "# Train on all data\n",
    "train_dataset = GCNDataset(\n",
    "    [f'../input/tfrecords/Fiehn_HILIC/train.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/valid.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/test.tfrec'], \n",
    "    batch_size, training=True)\n",
    "\n",
    "# build model (with default hyper-parameters)\n",
    "gcn_model = GCNModel()\n",
    "\n",
    "# fit model for {num_epochs} with a batch_size of {batch_size}\n",
    "gcn_model.fit(\n",
    "    train_dataset.get_iterator(), \n",
    "    epochs=num_epochs, verbose=1\n",
    ")\n",
    "\n",
    "# remcompile with vanilla gradient descent (SGD)\n",
    "gcn_model.compile(optimizer=tf.keras.optimizers.SGD())\n",
    "\n",
    "# save model\n",
    "tf.saved_model.save(gcn_model, f'../output/models/gcn_model_Fiehn_HILIC', serve_model(gcn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sal = saliency.Saliency(import_dir=f'../output/models/gcn_model_Fiehn_HILIC')\n",
    "\n",
    "# define new dataset (with training=False)\n",
    "dataset = GCNDataset(\n",
    "    [f'../input/tfrecords/Fiehn_HILIC/train.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/valid.tfrec', \n",
    "     f'../input/tfrecords/Fiehn_HILIC/test.tfrec'], \n",
    "    batch_size, training=False)\n",
    "\n",
    "# obtain dataset as a numpy iterator\n",
    "dataset = dataset.get_iterator()\n",
    "dataset = dataset.as_numpy_iterator()\n",
    "\n",
    "# loop over dataset in batches\n",
    "for batch in tqdm(dataset):\n",
    "    \n",
    "    # loop over each example in batch and compute its saliency map\n",
    "    # and finally save to file\n",
    "    for index in range(batch['label'].shape[0]):\n",
    "        A = batch['adjacency_matrix'][index]\n",
    "        H = batch['feature_matrix'][index]\n",
    "        y = batch['label'][index]\n",
    "        s = batch['string'][index][0]\n",
    "        i = batch['index'][index][0]\n",
    "        \n",
    "        saliency_map = sal.atom_importance(A, H, y)\n",
    "        \n",
    "        # build RDKit mol object from string (SMILES)\n",
    "        mol = transform_ops.mol_from_string(s.decode('utf-8'))\n",
    "        \n",
    "        # draw saliency map on 2-d representation of mol object and save to file\n",
    "        sal.draw_atom_saliency_on_mol(\n",
    "            mol, saliency_map, f'../output/saliency/mol_Fiehn_HILIC_{i}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train on RIKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "\n",
    "# Train on all data\n",
    "train_dataset = GCNDataset(\n",
    "    [f'../input/tfrecords/RIKEN/train.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/valid.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/test.tfrec'], \n",
    "    batch_size, training=True)\n",
    "\n",
    "# build model (with default hyper-parameters)\n",
    "gcn_model = GCNModel()\n",
    "\n",
    "# fit model for {num_epochs} with a batch_size of {batch_size}\n",
    "gcn_model.fit(\n",
    "    train_dataset.get_iterator(), \n",
    "    epochs=num_epochs, verbose=1\n",
    ")\n",
    "\n",
    "# remcompile with vanilla gradient descent (SGD)\n",
    "gcn_model.compile(optimizer=tf.keras.optimizers.SGD())\n",
    "\n",
    "# save model\n",
    "tf.saved_model.save(gcn_model, f'../output/models/gcn_model_RIKEN', serve_model(gcn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = saliency.Saliency(import_dir=f'../output/models/gcn_model_RIKEN')\n",
    "\n",
    "# define new dataset (with training=False)\n",
    "dataset = GCNDataset(\n",
    "    [f'../input/tfrecords/RIKEN/train.tfrec', \n",
    "     f'../input/tfrecords/RIKEN/valid.tfrec', \n",
    "     f'../input/tfrecords/RIKEN/test.tfrec'], \n",
    "    batch_size, training=False)\n",
    "\n",
    "# obtain dataset as a numpy iterator\n",
    "dataset = dataset.get_iterator()\n",
    "dataset = dataset.as_numpy_iterator()\n",
    "\n",
    "# loop over dataset in batches\n",
    "for batch in tqdm(dataset):\n",
    "    \n",
    "    # loop over each example in batch and compute its saliency map\n",
    "    # and finally save to file\n",
    "    for index in range(batch['label'].shape[0]):\n",
    "        A = batch['adjacency_matrix'][index]\n",
    "        H = batch['feature_matrix'][index]\n",
    "        y = batch['label'][index]\n",
    "        s = batch['string'][index][0]\n",
    "        i = batch['index'][index][0]\n",
    "        \n",
    "        saliency_map = sal.atom_importance(A, H, y)\n",
    "        \n",
    "        # build RDKit mol object from string (SMILES)\n",
    "        mol = transform_ops.mol_from_string(s.decode('utf-8'))\n",
    "        \n",
    "        # draw saliency map on 2-d representation of mol object and save to file\n",
    "        sal.draw_atom_saliency_on_mol(\n",
    "            mol, saliency_map, f'../output/saliency/mol_RIKEN_{i}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
