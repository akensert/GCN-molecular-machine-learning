{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing \n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Lipinski\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import DataStructs\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from ops import transform_ops\n",
    "from gcn.datasets import GCNDataset\n",
    "from gcn.models import GCNModel\n",
    "from gcn import saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hilic_dataset = GCNDataset(\n",
    "    [f'../input/tfrecords/Fiehn_HILIC/train.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/valid.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/test_1.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/test_2.tfrec'], \n",
    "    1, False).get_iterator()\n",
    "\n",
    "rplc_dataset = GCNDataset(\n",
    "    [f'../input/tfrecords/RIKEN/train.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/valid.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/test_1.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/test_2.tfrec'], \n",
    "    1, False\n",
    ").get_iterator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f69e5a97f644c0a74cbbfdc6b70596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_similarity_score(a, b):\n",
    "    mols = [Chem.MolFromSmiles(a), Chem.MolFromSmiles(b)]\n",
    "    fps = [Chem.RDKFingerprint(mol) for mol in mols]\n",
    "    score = DataStructs.FingerprintSimilarity(fps[0], fps[1])\n",
    "    return score\n",
    "\n",
    "\n",
    "hilic_data = []\n",
    "rplc_data = []\n",
    "\n",
    "for example_1 in tqdm(hilic_dataset):\n",
    "    for example_2 in rplc_dataset:\n",
    "\n",
    "        a = example_1['string'].numpy()[0][0].decode('utf-8')\n",
    "        b = example_2['string'].numpy()[0][0].decode('utf-8')\n",
    "        #a = Chem.CanonSmiles(a)\n",
    "        #b = Chem.CanonSmiles(b)\n",
    "        a = Chem.MolFromSmiles(a)\n",
    "        b = Chem.MolFromSmiles(b)\n",
    "        \n",
    "        if (a.HasSubstructMatch(b) and b.HasSubstructMatch(a)):\n",
    "            \n",
    "            A = example_1['adjacency_matrix'].numpy()[0]\n",
    "            H = example_1['feature_matrix'].numpy()[0]\n",
    "            y = example_1['label'].numpy()[0]\n",
    "            s = example_1['string'].numpy()[0][0].decode('utf-8')\n",
    "            i = example_1['index'].numpy()[0][0]\n",
    "            \n",
    "            hilic_data.append((A, H, y, a, i))\n",
    "            \n",
    "            A = example_2['adjacency_matrix'].numpy()[0]\n",
    "            H = example_2['feature_matrix'].numpy()[0]\n",
    "            y = example_2['label'].numpy()[0]\n",
    "            s = example_2['string'].numpy()[0][0].decode('utf-8')\n",
    "            j = example_2['index'].numpy()[0][0]\n",
    "            \n",
    "            rplc_data.append((A, H, y, b, j))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('../input/datasets/Fiehn_HILIC.csv')\n",
    "data2 = pd.read_csv('../input/datasets/RIKEN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18\n",
    "# 20\n",
    "# 33\n",
    "# 35\n",
    "# 36\n",
    "# 37\n",
    "# 58\n",
    "# 60\n",
    "# 69\n",
    "# 39\n",
    "# 1\n",
    "# 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 851 881\n",
      "1 295 141\n",
      "2 224 903\n",
      "3 218 330\n",
      "4 747 416\n",
      "5 386 416\n",
      "6 78 512\n",
      "7 779 936\n",
      "8 184 563\n",
      "9 218 945\n",
      "10 784 948\n",
      "11 228 951\n",
      "12 465 961\n",
      "13 84 811\n",
      "14 309 963\n",
      "15 778 964\n",
      "16 390 118\n",
      "17 221 997\n",
      "18 308 999\n",
      "19 227 139\n",
      "20 243 1020\n",
      "21 244 1021\n",
      "22 127 174\n",
      "23 302 201\n",
      "24 320 234\n",
      "25 139 238\n",
      "26 473 241\n",
      "27 240 250\n",
      "28 388 283\n",
      "29 141 294\n",
      "30 278 303\n",
      "31 662 315\n",
      "32 237 315\n",
      "33 290 322\n",
      "34 451 336\n",
      "35 247 358\n",
      "36 62 359\n",
      "37 247 386\n",
      "38 255 387\n",
      "39 263 392\n",
      "40 492 393\n",
      "41 695 393\n",
      "42 696 393\n",
      "43 214 397\n",
      "44 393 479\n",
      "45 231 519\n",
      "46 134 592\n",
      "47 233 593\n",
      "48 197 596\n",
      "49 198 599\n",
      "50 19 611\n",
      "51 311 617\n",
      "52 842 617\n",
      "53 403 629\n",
      "54 250 645\n",
      "55 297 652\n",
      "56 321 657\n",
      "57 307 716\n",
      "58 306 717\n",
      "59 225 725\n",
      "60 230 761\n",
      "61 84 798\n",
      "62 215 799\n",
      "63 278 814\n",
      "64 315 815\n",
      "65 491 817\n",
      "66 300 842\n",
      "67 424 846\n",
      "68 308 850\n",
      "69 316 856\n",
      "70 54 869\n",
      "71 253 870\n",
      "72 746 872\n",
      "73 22 876\n"
     ]
    }
   ],
   "source": [
    "# for i, (d, z) in enumerate(zip(rplc_data, hilic_data)):\n",
    "#     print(i, d[-1], z[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quercetin-3-O-glucosyl-6''-acetate Quercetin-3-O-beta-glucopyranosyl-6'-acetate\n"
     ]
    }
   ],
   "source": [
    "# print(data2.iloc[316].compound_name, data.iloc[856].compound_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair = 0\n",
    "# for example_1 in tqdm(hilic_dataset):\n",
    "#     for example_2 in rplc_dataset:\n",
    "\n",
    "#         a = example_1['string'].numpy()[0][0].decode('utf-8')\n",
    "#         b = example_2['string'].numpy()[0][0].decode('utf-8')\n",
    "\n",
    "#         score = compute_similarity_score(a, b)\n",
    "#         if score >= 1.0:\n",
    "\n",
    "#             A = example_1['adjacency_matrix'].numpy()[0]\n",
    "#             H = example_1['feature_matrix'].numpy()[0]\n",
    "#             y = example_1['label'].numpy()[0]\n",
    "#             s = example_1['string'].numpy()[0][0].decode('utf-8')\n",
    "#             i = example_1['index'].numpy()[0][0]\n",
    "            \n",
    "#             saliency_map = saliency_hilic.atom_importance(A, H, y)\n",
    "#             mol = transform_ops.mol_from_string(s)\n",
    "#             saliency_hilic.draw_atom_saliency_on_mol(\n",
    "#                 mol, saliency_map, f'../output/saliency/mol_pair_{pair}_Fiehn_HILIC_{i}.png')\n",
    "            \n",
    "            \n",
    "#             A = example_2['adjacency_matrix'].numpy()[0]\n",
    "#             H = example_2['feature_matrix'].numpy()[0]\n",
    "#             y = example_2['label'].numpy()[0]\n",
    "#             s = example_2['string'].numpy()[0][0].decode('utf-8')\n",
    "#             i = example_2['index'].numpy()[0][0]\n",
    "            \n",
    "#             saliency_map = saliency_rplc.atom_importance(A, H, y)\n",
    "#             mol = transform_ops.mol_from_string(s)\n",
    "#             saliency_rplc.draw_atom_saliency_on_mol(\n",
    "#                 mol, saliency_map, f'../output/saliency/mol_pair_{pair}_RIKEN_{i}.png')\n",
    "            \n",
    "            \n",
    "#             pair += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afd36acffff40db8c0687351d4eda9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def vanilla_atom_saliency(model, A, H, y):\n",
    "\n",
    "    # remove potential padding\n",
    "    keep_idx = np.where(A.sum(axis=1) != 0)[0]\n",
    "    H = tf.convert_to_tensor(H[keep_idx])[tf.newaxis]\n",
    "    A = tf.convert_to_tensor(A[keep_idx][:, keep_idx])[tf.newaxis]\n",
    "    y = tf.convert_to_tensor(y)[tf.newaxis]\n",
    "\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "        tape.watch(H)\n",
    "        y_pred = model([A, H], training=False)\n",
    "        loss = tf.compat.v1.losses.huber_loss(y, y_pred)\n",
    "    \n",
    "    gradients = tape.gradient(loss, H)\n",
    "    gradients = tf.abs(gradients)\n",
    "    return tf.reduce_sum(gradients[0], axis=1).numpy()\n",
    "\n",
    "\n",
    "def vanilla_bond_saliency(gcn_model, A, H, y):\n",
    "    \n",
    "    \n",
    "    idx_nonzero = tf.where(A > 0)\n",
    "    A_nonzero = tf.gather_nd(A, idx_nonzero)\n",
    "\n",
    "    y = tf.convert_to_tensor(y)[tf.newaxis]\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(A_nonzero)\n",
    "        A = tf.scatter_nd(idx_nonzero, A_nonzero, shape=A.shape)\n",
    "        y_pred = gcn_model([A[tf.newaxis], H[tf.newaxis]], training=False)\n",
    "        loss = tf.compat.v1.losses.huber_loss(y, y_pred)\n",
    "\n",
    "    gradients = tape.gradient(loss, A_nonzero)\n",
    "    gradients = tf.abs(gradients)\n",
    "    return gradients.numpy()#tf.math.segment_sum(gradients, idx_nonzero[:, 0])\n",
    "\n",
    "\n",
    "def integrated_atom_saliency(gcn_model, A, H, y, m_steps=20):\n",
    "    \"\"\"\n",
    "    Based on: https://www.tensorflow.org/tutorials/interpretability/integrated_gradients\n",
    "    And: https://github.com/stellargraph/stellargraph/blob/develop/stellargraph/interpretability/saliency_maps/integrated_gradients.py\n",
    "    \"\"\"\n",
    "    alphas = np.linspace(0.1, 1.0, m_steps)\n",
    "    \n",
    "    H_baseline = tf.zeros(H.shape, dtype=H.dtype)\n",
    "    \n",
    "    gradients_batch = tf.TensorArray(tf.float32, size=m_steps)\n",
    "    \n",
    "    y = tf.convert_to_tensor(y)[tf.newaxis]\n",
    "    \n",
    "    for i in tf.range(0, len(alphas), 1):\n",
    "        H_step = H_baseline + alphas[i] * (H - H_baseline)\n",
    "        with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "            tape.watch(H_step)\n",
    "            pred = gcn_model([A[tf.newaxis], H_step[tf.newaxis]], training=False)\n",
    "            loss = tf.compat.v1.losses.huber_loss(y, pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss, H_step)\n",
    "        \n",
    "        gradients_batch = gradients_batch.write(i, gradients)\n",
    "    \n",
    "    gradients_batch = gradients_batch.stack()\n",
    "    \n",
    "    # riemann_trapezoidal: https://www.tensorflow.org/tutorials/interpretability/integrated_gradients\n",
    "    integrated_gradients = (gradients_batch[:-1] + gradients_batch[1:]) / tf.constant(2.0)\n",
    "    integrated_gradients = tf.math.reduce_mean(integrated_gradients, axis=0)\n",
    "    \n",
    "    integrated_gradients = (H - H_baseline) * integrated_gradients\n",
    "    \n",
    "    return tf.reduce_sum(tf.abs(integrated_gradients), axis=-1).numpy()\n",
    "\n",
    "\n",
    "def integrated_atom_saliency2(gcn_model, A, H, y, m_steps=20):\n",
    "    \"\"\"\n",
    "    Based on: https://www.tensorflow.org/tutorials/interpretability/integrated_gradients\n",
    "    And: https://github.com/stellargraph/stellargraph/blob/develop/stellargraph/interpretability/saliency_maps/integrated_gradients.py\n",
    "    \"\"\"\n",
    "    alphas = np.linspace(0.1, 1.0, m_steps)\n",
    "    \n",
    "    H_baseline = tf.zeros(H.shape, dtype=H.dtype)\n",
    "    \n",
    "    gradients_batch = tf.TensorArray(tf.float32, size=m_steps)\n",
    "\n",
    "    for i in tf.range(0, len(alphas), 1):\n",
    "        H_step = H_baseline + alphas[i] * (H - H_baseline)\n",
    "        with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "            tape.watch(H_step)\n",
    "            pred = gcn_model([A[tf.newaxis], H_step[tf.newaxis]], training=False)[0]\n",
    "            \n",
    "            y = tf.constant(0.0)\n",
    "            y += tf.stop_gradient(pred)\n",
    "            y += 1.0\n",
    "            loss = tf.compat.v1.losses.huber_loss(y, pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss, H_step)\n",
    " \n",
    "        gradients_batch = gradients_batch.write(i, gradients)\n",
    "    \n",
    "    gradients_batch = gradients_batch.stack()\n",
    "    \n",
    "    # riemann_trapezoidal: https://www.tensorflow.org/tutorials/interpretability/integrated_gradients\n",
    "    integrated_gradients = (gradients_batch[:-1] + gradients_batch[1:]) / tf.constant(2.0)\n",
    "    integrated_gradients = tf.math.reduce_mean(integrated_gradients, axis=0)\n",
    "    \n",
    "    integrated_gradients = (H - H_baseline) * integrated_gradients\n",
    "    \n",
    "    return tf.reduce_sum(integrated_gradients, axis=-1).numpy() #* (y[0]-pred[0].numpy())\n",
    "\n",
    "\n",
    "def smoothgrad_atom_saliency(gcn_model, A, H, y, m_steps=50, noise=0.1):\n",
    "    \"\"\"\n",
    "    Based on: https://www.tensorflow.org/tutorials/interpretability/integrated_gradients\n",
    "    And: https://github.com/stellargraph/stellargraph/blob/develop/stellargraph/interpretability/saliency_maps/integrated_gradients.py\n",
    "    \"\"\"\n",
    "    \n",
    "    gradients_batch = tf.TensorArray(tf.float32, size=m_steps)\n",
    "\n",
    "    for i in tf.range(m_steps):\n",
    "        H_noisy = H + tf.random.normal(shape=(1, H.shape[1]), mean=0.0, stddev=noise)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(H_noisy)\n",
    "            pred = gcn_model([A[tf.newaxis], H_noisy[tf.newaxis]])[0]\n",
    "            loss = tf.compat.v1.losses.huber_loss(y, pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss, H_noisy)\n",
    "        \n",
    "        gradients_batch = gradients_batch.write(i, tf.abs(gradients))\n",
    "    \n",
    "    gradients_batch = gradients_batch.stack()\n",
    "    \n",
    "    avg_gradients = tf.math.reduce_mean(gradients_batch, axis=0)\n",
    "    \n",
    "    return tf.reduce_sum(avg_gradients, axis=-1).numpy()\n",
    "\n",
    "\n",
    "def integrated_bond_saliency(gcn_model, A, H, y, m_steps=20, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    Based on: https://www.tensorflow.org/tutorials/interpretability/integrated_gradients\n",
    "    And: https://github.com/stellargraph/stellargraph/blob/develop/stellargraph/interpretability/saliency_maps/integrated_gradients.py\n",
    "    \n",
    "    A = [[0, 1, 0, 1],\n",
    "         [1, 0, 0, 0],\n",
    "         [0, 0, 0, 1],\n",
    "         [1, 0, 1, 0]]  \n",
    "    S = [5.2, 4.1, 3.7, 0.6, 1.1, 3.2]\n",
    "    \n",
    "    --> AS = [[0,   5.2, 0,   4.1],\n",
    "              [3.7, 0,   0,   0  ],\n",
    "              [0,   0,   0,   0.6],\n",
    "              [1.1, 0,   3.2, 0]] \n",
    "    \"\"\"\n",
    "    alphas = np.linspace(0.0, 1.0, m_steps)\n",
    "    \n",
    "    idx_nonzero = tf.where(A > 0)\n",
    "    A_nonzero = tf.gather_nd(A, idx_nonzero)\n",
    "    y = tf.convert_to_tensor(y)[tf.newaxis]\n",
    "    \n",
    "    A_baseline = tf.zeros(A_nonzero.shape, dtype=A_nonzero.dtype) + epsilon\n",
    "    \n",
    "    gradients_batch = tf.TensorArray(tf.float32, size=m_steps)\n",
    "\n",
    "    for i in tf.range(0, len(alphas), 1):\n",
    "        A_step = A_baseline + alphas[i] * (A_nonzero - A_baseline)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(A_step)\n",
    "            A_step_ = tf.scatter_nd(idx_nonzero, A_step, shape=A.shape)\n",
    "            pred = gcn_model([A_step_[tf.newaxis], H[tf.newaxis]])\n",
    "            loss = tf.compat.v1.losses.huber_loss(y, pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss, A_step)\n",
    "        \n",
    "        gradients_batch = gradients_batch.write(i, gradients)\n",
    "    \n",
    "    gradients_batch = gradients_batch.stack()\n",
    "    \n",
    "    # riemann_trapezoidal: https://www.tensorflow.org/tutorials/interpretability/integrated_gradients\n",
    "    integrated_gradients = (gradients_batch[:-1] + gradients_batch[1:]) / tf.constant(2.0)\n",
    "    integrated_gradients = tf.math.reduce_mean(integrated_gradients, axis=0)\n",
    "    \n",
    "    integrated_gradients = (A_nonzero - A_baseline) * integrated_gradients\n",
    "    \n",
    "    return tf.abs(integrated_gradients).numpy()\n",
    "\n",
    "def vanilla_bond_saliency(gcn_model, A, H, y):\n",
    "    '''\n",
    "    A = [[0, 1, 0, 1],\n",
    "         [1, 0, 0, 0],\n",
    "         [0, 0, 0, 1],\n",
    "         [1, 0, 1, 0]]  \n",
    "    S = [5.2, 4.1, 3.7, 0.6, 1.1, 3.2]\n",
    "    \n",
    "    --> AS = [[0,   5.2, 0,   4.1],\n",
    "              [3.7, 0,   0,   0  ],\n",
    "              [0,   0,   0,   0.6],\n",
    "              [1.1, 0,   3.2, 0]] \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    idx_nonzero = tf.where(A > 0)\n",
    "    A_nonzero = tf.gather_nd(A, idx_nonzero)\n",
    "    y = tf.convert_to_tensor(y)[tf.newaxis]\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(A_nonzero)\n",
    "        A = tf.scatter_nd(idx_nonzero, A_nonzero, shape=A.shape)\n",
    "        y_pred = gcn_model([A[tf.newaxis], H[tf.newaxis]])\n",
    "        loss = tf.compat.v1.losses.huber_loss(y, y_pred)\n",
    "\n",
    "    gradients = tape.gradient(loss, A_nonzero)\n",
    "    gradients = tf.abs(gradients)\n",
    "    return gradients.numpy()#tf.math.segment_sum(gradients, idx_nonzero[:, 0])\n",
    "\n",
    "\n",
    "def draw_atom_saliency_on_mol(mol, saliency, path, size=(1000, 1000)):\n",
    "\n",
    "    if not os.path.isdir('/'.join(path.split('/')[:-1])):\n",
    "        os.makedirs('/'.join(path.split('/')[:-1]))\n",
    "\n",
    "    drawer = Draw.MolDraw2DCairo(*size)\n",
    "    drawer.drawOptions().bondLineWidth = 3\n",
    "\n",
    "    saliency = saliency / saliency.max()\n",
    "    \n",
    "    Draw.SimilarityMaps.GetSimilarityMapFromWeights(\n",
    "        mol=mol,\n",
    "        weights=[float(s) for s in saliency],\n",
    "        size=size,\n",
    "        coordScale=1.0,\n",
    "        colors='g',\n",
    "        alpha=0.4,\n",
    "        contourLines=10,\n",
    "        draw2d=drawer);\n",
    "\n",
    "    drawer.FinishDrawing()\n",
    "    drawer.WriteDrawingText(path)\n",
    "    \n",
    "\n",
    "for example_1 in tqdm(rplc_dataset.take(7)):\n",
    "    A = example_1['adjacency_matrix'].numpy()[0]\n",
    "    H = example_1['feature_matrix'].numpy()[0]\n",
    "    y = example_1['label'].numpy()[0]\n",
    "    s = example_1['string'].numpy()[0][0].decode('utf-8')\n",
    "    i = example_1['index'].numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff27175eb50>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "saliency_map = vanilla_bond_saliency(gcn_model_rplc, A, H, y)\n",
    "plt.plot(range(len(saliency_map)), saliency_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc6fcb93d10>]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "saliency_map = integrated_bond_saliency(gcn_model_rplc, A, H, y)\n",
    "plt.plot(range(len(saliency_map)), saliency_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Pre-condition Violation\n\tsize mismatch\n\tViolation occurred on line 295 in file Code/GraphMol/MolDraw2D/MolDraw2DUtils.cpp\n\tFailed Expression: locs.size() == weights.size()\n\tRDKIT: 2020.09.1\n\tBOOST: 1_73\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-30f4d1ca1b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msaliency_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvanilla_bond_saliency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_model_rplc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmol_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdraw_atom_saliency_on_mol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaliency_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bar/test_1.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-163-9037d175705e>\u001b[0m in \u001b[0;36mdraw_atom_saliency_on_mol\u001b[0;34m(mol, saliency, path, size)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mcontourLines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         draw2d=drawer);\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mdrawer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFinishDrawing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my-rdkit-env/lib/python3.7/site-packages/rdkit/Chem/Draw/SimilarityMaps.py\u001b[0m in \u001b[0;36mGetSimilarityMapFromWeights\u001b[0;34m(mol, weights, colorMap, scale, size, sigma, coordScale, step, colors, contourLines, alpha, draw2d, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridResolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextraGridPadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mDraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContourAndDrawGaussians\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigmas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnContours\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontourLines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mdraw2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclearBackground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mdraw2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDrawMolecule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Pre-condition Violation\n\tsize mismatch\n\tViolation occurred on line 295 in file Code/GraphMol/MolDraw2D/MolDraw2DUtils.cpp\n\tFailed Expression: locs.size() == weights.size()\n\tRDKIT: 2020.09.1\n\tBOOST: 1_73\n"
     ]
    }
   ],
   "source": [
    "saliency_map = vanilla_atom_saliency(gcn_model_rplc, A, H, y)\n",
    "mol = transform_ops.mol_from_string(s)\n",
    "draw_atom_saliency_on_mol(mol, saliency_map, 'bar/test_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_map = integrated_atom_saliency(gcn_model_rplc, A, H, y)\n",
    "mol = transform_ops.mol_from_string(s)\n",
    "draw_atom_saliency_on_mol(mol, saliency_map, f'bar/test_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 000 : lr 0.001000 : loss 1.574 : : 100%|██████████| 44/44 [00:01<00:00, 29.23it/s]\n",
      "epoch 001 : lr 0.001000 : loss 1.360 : : 100%|██████████| 44/44 [00:00<00:00, 102.24it/s]\n",
      "epoch 002 : lr 0.001000 : loss 1.263 : : 100%|██████████| 44/44 [00:00<00:00, 100.17it/s]\n",
      "epoch 003 : lr 0.001000 : loss 1.203 : : 100%|██████████| 44/44 [00:00<00:00, 100.42it/s]\n",
      "epoch 004 : lr 0.001000 : loss 1.157 : : 100%|██████████| 44/44 [00:00<00:00, 100.09it/s]\n",
      "epoch 005 : lr 0.001000 : loss 1.128 : : 100%|██████████| 44/44 [00:00<00:00, 103.01it/s]\n",
      "epoch 006 : lr 0.001000 : loss 1.104 : : 100%|██████████| 44/44 [00:00<00:00, 100.49it/s]\n",
      "epoch 007 : lr 0.001000 : loss 1.076 : : 100%|██████████| 44/44 [00:00<00:00, 101.16it/s]\n",
      "epoch 008 : lr 0.001000 : loss 1.056 : : 100%|██████████| 44/44 [00:00<00:00, 99.83it/s]\n",
      "epoch 009 : lr 0.001000 : loss 1.037 : : 100%|██████████| 44/44 [00:00<00:00, 99.58it/s]\n",
      "epoch 010 : lr 0.001000 : loss 1.018 : : 100%|██████████| 44/44 [00:00<00:00, 99.33it/s]\n",
      "epoch 011 : lr 0.001000 : loss 1.004 : : 100%|██████████| 44/44 [00:00<00:00, 97.84it/s]\n",
      "epoch 012 : lr 0.001000 : loss 0.999 : : 100%|██████████| 44/44 [00:00<00:00, 99.76it/s]\n",
      "epoch 013 : lr 0.001000 : loss 0.986 : : 100%|██████████| 44/44 [00:00<00:00, 98.49it/s]\n",
      "epoch 014 : lr 0.001000 : loss 0.971 : : 100%|██████████| 44/44 [00:00<00:00, 97.68it/s]\n",
      "epoch 015 : lr 0.001000 : loss 0.959 : : 100%|██████████| 44/44 [00:00<00:00, 97.55it/s]\n",
      "epoch 016 : lr 0.001000 : loss 0.946 : : 100%|██████████| 44/44 [00:00<00:00, 101.89it/s]\n",
      "epoch 017 : lr 0.001000 : loss 0.932 : : 100%|██████████| 44/44 [00:00<00:00, 99.66it/s]\n",
      "epoch 018 : lr 0.001000 : loss 0.920 : : 100%|██████████| 44/44 [00:00<00:00, 98.41it/s]\n",
      "epoch 019 : lr 0.001000 : loss 0.908 : : 100%|██████████| 44/44 [00:00<00:00, 100.70it/s]\n",
      "epoch 020 : lr 0.001000 : loss 0.896 : : 100%|██████████| 44/44 [00:00<00:00, 101.78it/s]\n",
      "epoch 021 : lr 0.001000 : loss 0.884 : : 100%|██████████| 44/44 [00:00<00:00, 101.18it/s]\n",
      "epoch 022 : lr 0.001000 : loss 0.875 : : 100%|██████████| 44/44 [00:00<00:00, 100.30it/s]\n",
      "epoch 023 : lr 0.001000 : loss 0.865 : : 100%|██████████| 44/44 [00:00<00:00, 101.58it/s]\n",
      "epoch 024 : lr 0.001000 : loss 0.856 : : 100%|██████████| 44/44 [00:00<00:00, 101.17it/s]\n",
      "epoch 025 : lr 0.001000 : loss 0.847 : : 100%|██████████| 44/44 [00:00<00:00, 99.30it/s]\n",
      "epoch 026 : lr 0.001000 : loss 0.838 : : 100%|██████████| 44/44 [00:00<00:00, 101.77it/s]\n",
      "epoch 027 : lr 0.001000 : loss 0.832 : : 100%|██████████| 44/44 [00:00<00:00, 100.31it/s]\n",
      "epoch 028 : lr 0.001000 : loss 0.825 : : 100%|██████████| 44/44 [00:00<00:00, 100.15it/s]\n",
      "epoch 029 : lr 0.001000 : loss 0.817 : : 100%|██████████| 44/44 [00:00<00:00, 98.69it/s]\n",
      "epoch 030 : lr 0.001000 : loss 0.809 : : 100%|██████████| 44/44 [00:00<00:00, 98.72it/s]\n",
      "epoch 031 : lr 0.001000 : loss 0.802 : : 100%|██████████| 44/44 [00:00<00:00, 97.02it/s]\n",
      "epoch 032 : lr 0.001000 : loss 0.795 : : 100%|██████████| 44/44 [00:00<00:00, 100.75it/s]\n",
      "epoch 033 : lr 0.001000 : loss 0.788 : : 100%|██████████| 44/44 [00:00<00:00, 99.16it/s]\n",
      "epoch 034 : lr 0.001000 : loss 0.783 : : 100%|██████████| 44/44 [00:00<00:00, 102.10it/s]\n",
      "epoch 035 : lr 0.001000 : loss 0.776 : : 100%|██████████| 44/44 [00:00<00:00, 100.22it/s]\n",
      "epoch 036 : lr 0.001000 : loss 0.770 : : 100%|██████████| 44/44 [00:00<00:00, 99.31it/s]\n",
      "epoch 037 : lr 0.001000 : loss 0.764 : : 100%|██████████| 44/44 [00:00<00:00, 99.78it/s]\n",
      "epoch 038 : lr 0.001000 : loss 0.759 : : 100%|██████████| 44/44 [00:00<00:00, 100.58it/s]\n",
      "epoch 039 : lr 0.001000 : loss 0.753 : : 100%|██████████| 44/44 [00:00<00:00, 99.08it/s]\n",
      "epoch 040 : lr 0.001000 : loss 0.748 : : 100%|██████████| 44/44 [00:00<00:00, 99.45it/s]\n",
      "epoch 041 : lr 0.001000 : loss 0.743 : : 100%|██████████| 44/44 [00:00<00:00, 98.31it/s]\n",
      "epoch 042 : lr 0.001000 : loss 0.737 : : 100%|██████████| 44/44 [00:00<00:00, 101.15it/s]\n",
      "epoch 043 : lr 0.001000 : loss 0.733 : : 100%|██████████| 44/44 [00:00<00:00, 100.50it/s]\n",
      "epoch 044 : lr 0.001000 : loss 0.728 : : 100%|██████████| 44/44 [00:00<00:00, 101.25it/s]\n",
      "epoch 045 : lr 0.001000 : loss 0.724 : : 100%|██████████| 44/44 [00:00<00:00, 99.28it/s]\n",
      "epoch 046 : lr 0.001000 : loss 0.719 : : 100%|██████████| 44/44 [00:00<00:00, 100.20it/s]\n",
      "epoch 047 : lr 0.001000 : loss 0.715 : : 100%|██████████| 44/44 [00:00<00:00, 101.38it/s]\n",
      "epoch 048 : lr 0.001000 : loss 0.710 : : 100%|██████████| 44/44 [00:00<00:00, 101.94it/s]\n",
      "epoch 049 : lr 0.001000 : loss 0.706 : : 100%|██████████| 44/44 [00:00<00:00, 98.86it/s]\n",
      "epoch 050 : lr 0.001000 : loss 0.702 : : 100%|██████████| 44/44 [00:00<00:00, 99.00it/s]\n",
      "epoch 051 : lr 0.001000 : loss 0.698 : : 100%|██████████| 44/44 [00:00<00:00, 99.13it/s]\n",
      "epoch 052 : lr 0.001000 : loss 0.694 : : 100%|██████████| 44/44 [00:00<00:00, 98.64it/s]\n",
      "epoch 053 : lr 0.001000 : loss 0.691 : : 100%|██████████| 44/44 [00:00<00:00, 97.04it/s]\n",
      "epoch 054 : lr 0.001000 : loss 0.687 : : 100%|██████████| 44/44 [00:00<00:00, 99.20it/s]\n",
      "epoch 055 : lr 0.001000 : loss 0.683 : : 100%|██████████| 44/44 [00:00<00:00, 97.94it/s]\n",
      "epoch 056 : lr 0.001000 : loss 0.679 : : 100%|██████████| 44/44 [00:00<00:00, 99.14it/s]\n",
      "epoch 057 : lr 0.001000 : loss 0.675 : : 100%|██████████| 44/44 [00:00<00:00, 99.26it/s]\n",
      "epoch 058 : lr 0.001000 : loss 0.672 : : 100%|██████████| 44/44 [00:00<00:00, 101.43it/s]\n",
      "epoch 059 : lr 0.001000 : loss 0.668 : : 100%|██████████| 44/44 [00:00<00:00, 101.17it/s]\n",
      "epoch 060 : lr 0.001000 : loss 0.665 : : 100%|██████████| 44/44 [00:00<00:00, 100.90it/s]\n",
      "epoch 061 : lr 0.001000 : loss 0.661 : : 100%|██████████| 44/44 [00:00<00:00, 99.64it/s]\n",
      "epoch 062 : lr 0.001000 : loss 0.658 : : 100%|██████████| 44/44 [00:00<00:00, 97.07it/s]\n",
      "epoch 063 : lr 0.001000 : loss 0.655 : : 100%|██████████| 44/44 [00:00<00:00, 99.70it/s]\n",
      "epoch 064 : lr 0.001000 : loss 0.651 : : 100%|██████████| 44/44 [00:00<00:00, 98.75it/s]\n",
      "epoch 065 : lr 0.001000 : loss 0.648 : : 100%|██████████| 44/44 [00:00<00:00, 95.91it/s]\n",
      "epoch 066 : lr 0.001000 : loss 0.645 : : 100%|██████████| 44/44 [00:00<00:00, 98.95it/s]\n",
      "epoch 067 : lr 0.001000 : loss 0.642 : : 100%|██████████| 44/44 [00:00<00:00, 100.10it/s]\n",
      "epoch 068 : lr 0.001000 : loss 0.639 : : 100%|██████████| 44/44 [00:00<00:00, 98.02it/s]\n",
      "epoch 069 : lr 0.001000 : loss 0.636 : : 100%|██████████| 44/44 [00:00<00:00, 99.88it/s]\n",
      "epoch 070 : lr 0.001000 : loss 0.633 : : 100%|██████████| 44/44 [00:00<00:00, 99.21it/s]\n",
      "epoch 071 : lr 0.001000 : loss 0.630 : : 100%|██████████| 44/44 [00:00<00:00, 89.63it/s]\n",
      "epoch 072 : lr 0.001000 : loss 0.627 : : 100%|██████████| 44/44 [00:00<00:00, 96.97it/s]\n",
      "epoch 073 : lr 0.001000 : loss 0.624 : : 100%|██████████| 44/44 [00:00<00:00, 96.72it/s]\n",
      "epoch 074 : lr 0.001000 : loss 0.621 : : 100%|██████████| 44/44 [00:00<00:00, 94.05it/s]\n",
      "epoch 075 : lr 0.001000 : loss 0.618 : : 100%|██████████| 44/44 [00:00<00:00, 97.75it/s]\n",
      "epoch 076 : lr 0.001000 : loss 0.615 : : 100%|██████████| 44/44 [00:00<00:00, 89.25it/s]\n",
      "epoch 077 : lr 0.001000 : loss 0.612 : : 100%|██████████| 44/44 [00:00<00:00, 94.81it/s]\n",
      "epoch 078 : lr 0.001000 : loss 0.609 : : 100%|██████████| 44/44 [00:00<00:00, 101.29it/s]\n",
      "epoch 079 : lr 0.001000 : loss 0.606 : : 100%|██████████| 44/44 [00:00<00:00, 103.06it/s]\n",
      "epoch 080 : lr 0.001000 : loss 0.603 : : 100%|██████████| 44/44 [00:00<00:00, 102.64it/s]\n",
      "epoch 081 : lr 0.000100 : loss 0.600 : : 100%|██████████| 44/44 [00:00<00:00, 104.34it/s]\n",
      "epoch 082 : lr 0.000100 : loss 0.597 : : 100%|██████████| 44/44 [00:00<00:00, 103.27it/s]\n",
      "epoch 083 : lr 0.000100 : loss 0.594 : : 100%|██████████| 44/44 [00:00<00:00, 102.98it/s]\n",
      "epoch 084 : lr 0.000100 : loss 0.591 : : 100%|██████████| 44/44 [00:00<00:00, 103.05it/s]\n",
      "epoch 085 : lr 0.000100 : loss 0.587 : : 100%|██████████| 44/44 [00:00<00:00, 94.35it/s]\n",
      "epoch 086 : lr 0.000100 : loss 0.584 : : 100%|██████████| 44/44 [00:00<00:00, 92.52it/s]\n",
      "epoch 087 : lr 0.000100 : loss 0.582 : : 100%|██████████| 44/44 [00:00<00:00, 104.30it/s]\n",
      "epoch 088 : lr 0.000100 : loss 0.579 : : 100%|██████████| 44/44 [00:00<00:00, 102.26it/s]\n",
      "epoch 089 : lr 0.000100 : loss 0.576 : : 100%|██████████| 44/44 [00:00<00:00, 102.54it/s]\n",
      "epoch 090 : lr 0.000100 : loss 0.573 : : 100%|██████████| 44/44 [00:00<00:00, 105.48it/s]\n",
      "epoch 091 : lr 0.000100 : loss 0.570 : : 100%|██████████| 44/44 [00:00<00:00, 104.16it/s]\n",
      "epoch 092 : lr 0.000100 : loss 0.568 : : 100%|██████████| 44/44 [00:00<00:00, 103.80it/s]\n",
      "epoch 093 : lr 0.000100 : loss 0.565 : : 100%|██████████| 44/44 [00:00<00:00, 104.98it/s]\n",
      "epoch 094 : lr 0.000100 : loss 0.563 : : 100%|██████████| 44/44 [00:00<00:00, 102.00it/s]\n",
      "epoch 095 : lr 0.000100 : loss 0.560 : : 100%|██████████| 44/44 [00:00<00:00, 102.98it/s]\n",
      "epoch 096 : lr 0.000100 : loss 0.558 : : 100%|██████████| 44/44 [00:00<00:00, 103.31it/s]\n",
      "epoch 097 : lr 0.000100 : loss 0.555 : : 100%|██████████| 44/44 [00:00<00:00, 102.81it/s]\n",
      "epoch 098 : lr 0.000100 : loss 0.553 : : 100%|██████████| 44/44 [00:00<00:00, 98.84it/s]\n",
      "epoch 099 : lr 0.000100 : loss 0.551 : : 100%|██████████| 44/44 [00:00<00:00, 103.41it/s]\n",
      "epoch 000 : lr 0.001000 : loss 1.397 : : 100%|██████████| 27/27 [00:00<00:00, 28.94it/s]\n",
      "epoch 001 : lr 0.001000 : loss 1.122 : : 100%|██████████| 27/27 [00:00<00:00, 96.89it/s]\n",
      "epoch 002 : lr 0.001000 : loss 0.980 : : 100%|██████████| 27/27 [00:00<00:00, 93.95it/s]\n",
      "epoch 003 : lr 0.001000 : loss 0.893 : : 100%|██████████| 27/27 [00:00<00:00, 95.72it/s]\n",
      "epoch 004 : lr 0.001000 : loss 0.839 : : 100%|██████████| 27/27 [00:00<00:00, 92.73it/s]\n",
      "epoch 005 : lr 0.001000 : loss 0.808 : : 100%|██████████| 27/27 [00:00<00:00, 96.80it/s]\n",
      "epoch 006 : lr 0.001000 : loss 0.776 : : 100%|██████████| 27/27 [00:00<00:00, 95.66it/s]\n",
      "epoch 007 : lr 0.001000 : loss 0.755 : : 100%|██████████| 27/27 [00:00<00:00, 91.28it/s]\n",
      "epoch 008 : lr 0.001000 : loss 0.735 : : 100%|██████████| 27/27 [00:00<00:00, 95.34it/s]\n",
      "epoch 009 : lr 0.001000 : loss 0.720 : : 100%|██████████| 27/27 [00:00<00:00, 96.13it/s]\n",
      "epoch 010 : lr 0.001000 : loss 0.703 : : 100%|██████████| 27/27 [00:00<00:00, 94.10it/s]\n",
      "epoch 011 : lr 0.001000 : loss 0.685 : : 100%|██████████| 27/27 [00:00<00:00, 93.43it/s]\n",
      "epoch 012 : lr 0.001000 : loss 0.670 : : 100%|██████████| 27/27 [00:00<00:00, 96.53it/s]\n",
      "epoch 013 : lr 0.001000 : loss 0.659 : : 100%|██████████| 27/27 [00:00<00:00, 97.34it/s]\n",
      "epoch 014 : lr 0.001000 : loss 0.650 : : 100%|██████████| 27/27 [00:00<00:00, 97.65it/s]\n",
      "epoch 015 : lr 0.001000 : loss 0.637 : : 100%|██████████| 27/27 [00:00<00:00, 96.30it/s]\n",
      "epoch 016 : lr 0.001000 : loss 0.625 : : 100%|██████████| 27/27 [00:00<00:00, 94.63it/s]\n",
      "epoch 017 : lr 0.001000 : loss 0.614 : : 100%|██████████| 27/27 [00:00<00:00, 94.75it/s]\n",
      "epoch 018 : lr 0.001000 : loss 0.604 : : 100%|██████████| 27/27 [00:00<00:00, 97.33it/s]\n",
      "epoch 019 : lr 0.001000 : loss 0.593 : : 100%|██████████| 27/27 [00:00<00:00, 94.35it/s]\n",
      "epoch 020 : lr 0.001000 : loss 0.583 : : 100%|██████████| 27/27 [00:00<00:00, 94.53it/s]\n",
      "epoch 021 : lr 0.001000 : loss 0.576 : : 100%|██████████| 27/27 [00:00<00:00, 96.36it/s]\n",
      "epoch 022 : lr 0.001000 : loss 0.570 : : 100%|██████████| 27/27 [00:00<00:00, 97.69it/s]\n",
      "epoch 023 : lr 0.001000 : loss 0.563 : : 100%|██████████| 27/27 [00:00<00:00, 96.79it/s]\n",
      "epoch 024 : lr 0.001000 : loss 0.556 : : 100%|██████████| 27/27 [00:00<00:00, 94.88it/s]\n",
      "epoch 025 : lr 0.001000 : loss 0.548 : : 100%|██████████| 27/27 [00:00<00:00, 95.63it/s]\n",
      "epoch 026 : lr 0.001000 : loss 0.541 : : 100%|██████████| 27/27 [00:00<00:00, 96.86it/s]\n",
      "epoch 027 : lr 0.001000 : loss 0.535 : : 100%|██████████| 27/27 [00:00<00:00, 97.50it/s]\n",
      "epoch 028 : lr 0.001000 : loss 0.528 : : 100%|██████████| 27/27 [00:00<00:00, 96.38it/s]\n",
      "epoch 029 : lr 0.001000 : loss 0.523 : : 100%|██████████| 27/27 [00:00<00:00, 95.71it/s]\n",
      "epoch 030 : lr 0.001000 : loss 0.519 : : 100%|██████████| 27/27 [00:00<00:00, 97.13it/s]\n",
      "epoch 031 : lr 0.001000 : loss 0.514 : : 100%|██████████| 27/27 [00:00<00:00, 93.75it/s]\n",
      "epoch 032 : lr 0.001000 : loss 0.509 : : 100%|██████████| 27/27 [00:00<00:00, 95.87it/s]\n",
      "epoch 033 : lr 0.001000 : loss 0.505 : : 100%|██████████| 27/27 [00:00<00:00, 93.72it/s]\n",
      "epoch 034 : lr 0.001000 : loss 0.500 : : 100%|██████████| 27/27 [00:00<00:00, 95.23it/s]\n",
      "epoch 035 : lr 0.001000 : loss 0.495 : : 100%|██████████| 27/27 [00:00<00:00, 96.59it/s]\n",
      "epoch 036 : lr 0.001000 : loss 0.491 : : 100%|██████████| 27/27 [00:00<00:00, 94.30it/s]\n",
      "epoch 037 : lr 0.001000 : loss 0.488 : : 100%|██████████| 27/27 [00:00<00:00, 98.02it/s]\n",
      "epoch 038 : lr 0.001000 : loss 0.484 : : 100%|██████████| 27/27 [00:00<00:00, 94.08it/s]\n",
      "epoch 039 : lr 0.001000 : loss 0.480 : : 100%|██████████| 27/27 [00:00<00:00, 96.10it/s]\n",
      "epoch 040 : lr 0.001000 : loss 0.476 : : 100%|██████████| 27/27 [00:00<00:00, 95.39it/s]\n",
      "epoch 041 : lr 0.001000 : loss 0.473 : : 100%|██████████| 27/27 [00:00<00:00, 93.89it/s]\n",
      "epoch 042 : lr 0.001000 : loss 0.471 : : 100%|██████████| 27/27 [00:00<00:00, 94.45it/s]\n",
      "epoch 043 : lr 0.001000 : loss 0.468 : : 100%|██████████| 27/27 [00:00<00:00, 98.32it/s]\n",
      "epoch 044 : lr 0.001000 : loss 0.464 : : 100%|██████████| 27/27 [00:00<00:00, 94.73it/s]\n",
      "epoch 045 : lr 0.001000 : loss 0.460 : : 100%|██████████| 27/27 [00:00<00:00, 96.42it/s]\n",
      "epoch 046 : lr 0.001000 : loss 0.456 : : 100%|██████████| 27/27 [00:00<00:00, 95.77it/s]\n",
      "epoch 047 : lr 0.001000 : loss 0.452 : : 100%|██████████| 27/27 [00:00<00:00, 95.96it/s]\n",
      "epoch 048 : lr 0.001000 : loss 0.450 : : 100%|██████████| 27/27 [00:00<00:00, 95.93it/s]\n",
      "epoch 049 : lr 0.001000 : loss 0.447 : : 100%|██████████| 27/27 [00:00<00:00, 93.87it/s]\n",
      "epoch 050 : lr 0.001000 : loss 0.444 : : 100%|██████████| 27/27 [00:00<00:00, 97.43it/s]\n",
      "epoch 051 : lr 0.001000 : loss 0.441 : : 100%|██████████| 27/27 [00:00<00:00, 96.01it/s]\n",
      "epoch 052 : lr 0.001000 : loss 0.437 : : 100%|██████████| 27/27 [00:00<00:00, 94.93it/s]\n",
      "epoch 053 : lr 0.001000 : loss 0.435 : : 100%|██████████| 27/27 [00:00<00:00, 96.66it/s]\n",
      "epoch 054 : lr 0.001000 : loss 0.432 : : 100%|██████████| 27/27 [00:00<00:00, 95.94it/s]\n",
      "epoch 055 : lr 0.001000 : loss 0.428 : : 100%|██████████| 27/27 [00:00<00:00, 96.14it/s]\n",
      "epoch 056 : lr 0.001000 : loss 0.426 : : 100%|██████████| 27/27 [00:00<00:00, 93.49it/s]\n",
      "epoch 057 : lr 0.001000 : loss 0.423 : : 100%|██████████| 27/27 [00:00<00:00, 94.48it/s]\n",
      "epoch 058 : lr 0.001000 : loss 0.420 : : 100%|██████████| 27/27 [00:00<00:00, 96.20it/s]\n",
      "epoch 059 : lr 0.001000 : loss 0.418 : : 100%|██████████| 27/27 [00:00<00:00, 94.11it/s]\n",
      "epoch 060 : lr 0.001000 : loss 0.415 : : 100%|██████████| 27/27 [00:00<00:00, 96.24it/s]\n",
      "epoch 061 : lr 0.001000 : loss 0.413 : : 100%|██████████| 27/27 [00:00<00:00, 96.83it/s]\n",
      "epoch 062 : lr 0.001000 : loss 0.410 : : 100%|██████████| 27/27 [00:00<00:00, 94.64it/s]\n",
      "epoch 063 : lr 0.001000 : loss 0.408 : : 100%|██████████| 27/27 [00:00<00:00, 93.03it/s]\n",
      "epoch 064 : lr 0.001000 : loss 0.405 : : 100%|██████████| 27/27 [00:00<00:00, 95.23it/s]\n",
      "epoch 065 : lr 0.001000 : loss 0.403 : : 100%|██████████| 27/27 [00:00<00:00, 92.17it/s]\n",
      "epoch 066 : lr 0.001000 : loss 0.401 : : 100%|██████████| 27/27 [00:00<00:00, 92.64it/s]\n",
      "epoch 067 : lr 0.001000 : loss 0.399 : : 100%|██████████| 27/27 [00:00<00:00, 95.66it/s]\n",
      "epoch 068 : lr 0.001000 : loss 0.397 : : 100%|██████████| 27/27 [00:00<00:00, 95.28it/s]\n",
      "epoch 069 : lr 0.001000 : loss 0.395 : : 100%|██████████| 27/27 [00:00<00:00, 96.61it/s]\n",
      "epoch 070 : lr 0.001000 : loss 0.393 : : 100%|██████████| 27/27 [00:00<00:00, 95.37it/s]\n",
      "epoch 071 : lr 0.001000 : loss 0.390 : : 100%|██████████| 27/27 [00:00<00:00, 96.71it/s]\n",
      "epoch 072 : lr 0.001000 : loss 0.388 : : 100%|██████████| 27/27 [00:00<00:00, 94.95it/s]\n",
      "epoch 073 : lr 0.001000 : loss 0.387 : : 100%|██████████| 27/27 [00:00<00:00, 95.49it/s]\n",
      "epoch 074 : lr 0.001000 : loss 0.385 : : 100%|██████████| 27/27 [00:00<00:00, 96.41it/s]\n",
      "epoch 075 : lr 0.001000 : loss 0.383 : : 100%|██████████| 27/27 [00:00<00:00, 94.49it/s]\n",
      "epoch 076 : lr 0.001000 : loss 0.381 : : 100%|██████████| 27/27 [00:00<00:00, 93.93it/s]\n",
      "epoch 077 : lr 0.001000 : loss 0.379 : : 100%|██████████| 27/27 [00:00<00:00, 96.41it/s]\n",
      "epoch 078 : lr 0.001000 : loss 0.377 : : 100%|██████████| 27/27 [00:00<00:00, 95.97it/s]\n",
      "epoch 079 : lr 0.001000 : loss 0.375 : : 100%|██████████| 27/27 [00:00<00:00, 94.05it/s]\n",
      "epoch 080 : lr 0.001000 : loss 0.373 : : 100%|██████████| 27/27 [00:00<00:00, 94.36it/s]\n",
      "epoch 081 : lr 0.000100 : loss 0.371 : : 100%|██████████| 27/27 [00:00<00:00, 96.22it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 082 : lr 0.000100 : loss 0.369 : : 100%|██████████| 27/27 [00:00<00:00, 93.79it/s]\n",
      "epoch 083 : lr 0.000100 : loss 0.367 : : 100%|██████████| 27/27 [00:00<00:00, 95.82it/s]\n",
      "epoch 084 : lr 0.000100 : loss 0.365 : : 100%|██████████| 27/27 [00:00<00:00, 93.37it/s]\n",
      "epoch 085 : lr 0.000100 : loss 0.363 : : 100%|██████████| 27/27 [00:00<00:00, 91.51it/s]\n",
      "epoch 086 : lr 0.000100 : loss 0.361 : : 100%|██████████| 27/27 [00:00<00:00, 93.48it/s]\n",
      "epoch 087 : lr 0.000100 : loss 0.359 : : 100%|██████████| 27/27 [00:00<00:00, 90.83it/s]\n",
      "epoch 088 : lr 0.000100 : loss 0.357 : : 100%|██████████| 27/27 [00:00<00:00, 83.64it/s]\n",
      "epoch 089 : lr 0.000100 : loss 0.356 : : 100%|██████████| 27/27 [00:00<00:00, 79.26it/s]\n",
      "epoch 090 : lr 0.000100 : loss 0.354 : : 100%|██████████| 27/27 [00:00<00:00, 88.19it/s]\n",
      "epoch 091 : lr 0.000100 : loss 0.352 : : 100%|██████████| 27/27 [00:00<00:00, 86.60it/s]\n",
      "epoch 092 : lr 0.000100 : loss 0.350 : : 100%|██████████| 27/27 [00:00<00:00, 88.07it/s]\n",
      "epoch 093 : lr 0.000100 : loss 0.349 : : 100%|██████████| 27/27 [00:00<00:00, 91.82it/s]\n",
      "epoch 094 : lr 0.000100 : loss 0.347 : : 100%|██████████| 27/27 [00:00<00:00, 94.84it/s]\n",
      "epoch 095 : lr 0.000100 : loss 0.345 : : 100%|██████████| 27/27 [00:00<00:00, 88.71it/s]\n",
      "epoch 096 : lr 0.000100 : loss 0.344 : : 100%|██████████| 27/27 [00:00<00:00, 88.26it/s]\n",
      "epoch 097 : lr 0.000100 : loss 0.342 : : 100%|██████████| 27/27 [00:00<00:00, 93.23it/s]\n",
      "epoch 098 : lr 0.000100 : loss 0.341 : : 100%|██████████| 27/27 [00:00<00:00, 91.44it/s]\n",
      "epoch 099 : lr 0.000100 : loss 0.339 : : 100%|██████████| 27/27 [00:00<00:00, 95.14it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "\n",
    "# Train on all data\n",
    "train_dataset_hilic = GCNDataset(\n",
    "    [f'../input/tfrecords/Fiehn_HILIC/train.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/valid.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/test_1.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/test_2.tfrec'], \n",
    "    batch_size, training=True)\n",
    "\n",
    "# build model (with default hyper-parameters)\n",
    "gcn_model_hilic = GCNModel(gconv_units=[128, 128,], gconv_activation='tanh', dense_activation='tanh')\n",
    "\n",
    "# fit model for {num_epochs} with a batch_size of {batch_size}\n",
    "gcn_model_hilic.fit(\n",
    "    train_dataset_hilic.get_iterator(), \n",
    "    epochs=num_epochs, verbose=1\n",
    ")\n",
    "\n",
    "gcn_model_hilic.compile(optimizer=tf.keras.optimizers.SGD())\n",
    "\n",
    "\n",
    "# Train on all data\n",
    "train_dataset_rplc = GCNDataset(\n",
    "    [f'../input/tfrecords/RIKEN/train.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/valid.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/test_1.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/test_2.tfrec'], \n",
    "    batch_size, training=True)\n",
    "\n",
    "# build model (with default hyper-parameters)\n",
    "gcn_model_rplc = GCNModel(gconv_units=[128, 128,], gconv_activation='tanh', dense_activation='tanh')\n",
    "\n",
    "# fit model for {num_epochs} with a batch_size of {batch_size}\n",
    "gcn_model_rplc.fit(\n",
    "    train_dataset_rplc.get_iterator(), \n",
    "    epochs=num_epochs, verbose=1\n",
    ")\n",
    "\n",
    "gcn_model_rplc.compile(optimizer=tf.keras.optimizers.SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4c41041f0b4d97b4354c6960140cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f7bec68ad50>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/alex/miniconda3/envs/my-rdkit-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    return outflag  File \"<ipython-input-14-35a51ab75bf3>\", line 14, in <module>\n",
      "    saliency_map = integrated_atom_saliency(gcn_model_rplc, A, H, y)  File \"<ipython-input-4-cd4dff36938c>\", line 58, in integrated_atom_saliency\n",
      "    gradients = tape.gradient(loss, H_step)  File \"/home/alex/miniconda3/envs/my-rdkit-env/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n",
      "    error_in_function=error_in_function)\n",
      "==================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0dc100b3d247809a87fa1010900e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ed9e96da5348219d64d602f0214566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2165a2e25b4f4e389e70f296af532fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee2978aaae54f5eb45ee0bb5d914071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "train_dataset_hilic = GCNDataset(\n",
    "    [f'../input/tfrecords/Fiehn_HILIC/train.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/valid.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/test_1.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/test_2.tfrec'], \n",
    "    batch_size, training=True)\n",
    "\n",
    "train_dataset_rplc = GCNDataset(\n",
    "    [f'../input/tfrecords/RIKEN/train.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/valid.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/test_1.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/test_2.tfrec'], \n",
    "    batch_size, training=True)\n",
    "\n",
    "gcn_model_hilic = GCNModel(dense_dropout=0.2)\n",
    "\n",
    "gcn_model_rplc = GCNModel(dense_dropout=0.2)\n",
    "\n",
    "\n",
    "hilic_saliency_map_vanilla = []\n",
    "rplc_saliency_map_vanilla = []\n",
    "hilic_saliency_map_integrated = []\n",
    "rplc_saliency_map_integrated = []\n",
    "\n",
    "for epoch in tqdm(range(4)):\n",
    "\n",
    "    gcn_model_hilic.fit(\n",
    "        train_dataset_hilic.get_iterator(), \n",
    "        epochs=200, verbose=0\n",
    "    )\n",
    "\n",
    "    gcn_model_rplc.fit(\n",
    "        train_dataset_rplc.get_iterator(), \n",
    "        epochs=200, verbose=0\n",
    "    )\n",
    "    \n",
    "\n",
    "    for k, (example_1, example_2) in tqdm(enumerate(zip(hilic_data, rplc_data))):\n",
    "\n",
    "        (A, H, y, s, i) = example_1\n",
    "        saliency_map = vanilla_atom_saliency(gcn_model_hilic, A, H, y)\n",
    "        if epoch == 0:\n",
    "            hilic_saliency_map_vanilla.append(saliency_map)\n",
    "        else:\n",
    "            hilic_saliency_map_vanilla[k] += saliency_map\n",
    "\n",
    "        (A, H, y, s, i) = example_2\n",
    "        saliency_map = vanilla_atom_saliency(gcn_model_rplc, A, H, y)\n",
    "        if epoch == 0:\n",
    "            rplc_saliency_map_vanilla.append(saliency_map)\n",
    "        else:\n",
    "            rplc_saliency_map_vanilla[k] += saliency_map\n",
    "\n",
    "        (A, H, y, s, i) = example_1\n",
    "        saliency_map = integrated_atom_saliency(gcn_model_hilic, A, H, y)\n",
    "        if epoch == 0:\n",
    "            hilic_saliency_map_integrated.append(saliency_map)\n",
    "        else:\n",
    "            hilic_saliency_map_integrated[k] += saliency_map\n",
    "\n",
    "        (A, H, y, s, i) = example_2\n",
    "        saliency_map = integrated_atom_saliency(gcn_model_rplc, A, H, y)\n",
    "        if epoch == 0:\n",
    "            rplc_saliency_map_integrated.append(saliency_map)\n",
    "        else:\n",
    "            rplc_saliency_map_integrated[k] += saliency_map\n",
    "\n",
    "\n",
    "#         #print(len(rplc_saliency_map_integrated), i)\n",
    "        \n",
    "pair = 0     \n",
    "for example_1, example_2, saliency_map_1, saliency_map_2 in zip(\n",
    "    hilic_data, rplc_data, hilic_saliency_map_vanilla, rplc_saliency_map_vanilla):\n",
    "\n",
    "    (A, H, y, mol, i) = example_1\n",
    "\n",
    "   #mol = transform_ops.mol_from_string(s)\n",
    "    draw_atom_saliency_on_mol(\n",
    "        mol, saliency_map_1, \n",
    "        f'../output/saliency/vanilla/Fiehn-HILIC_{pair}-{i}-{epoch}.png')\n",
    "\n",
    "    (A, H, y, mol, i) = example_2\n",
    "\n",
    "    #mol = transform_ops.mol_from_string(s)\n",
    "    draw_atom_saliency_on_mol(\n",
    "        mol, saliency_map_2, \n",
    "        f'../output/saliency/vanilla/RIKEN_{pair}-{i}-{epoch}.png')\n",
    "\n",
    "    pair += 1\n",
    "    \n",
    "    \n",
    "pair = 0     \n",
    "for example_1, example_2, saliency_map_1, saliency_map_2 in zip(\n",
    "    hilic_data, rplc_data, hilic_saliency_map_integrated, rplc_saliency_map_integrated):\n",
    "\n",
    "    (A, H, y, mol, i) = example_1\n",
    "\n",
    "    #mol = transform_ops.mol_from_string(s)\n",
    "    draw_atom_saliency_on_mol(\n",
    "        mol, saliency_map_1, \n",
    "        f'../output/saliency/integrated/Fiehn-HILIC_{pair}-{i}-{epoch}.png')\n",
    "\n",
    "    (A, H, y, mol, i) = example_2\n",
    "\n",
    "    #mol = transform_ops.mol_from_string(s)\n",
    "    draw_atom_saliency_on_mol(\n",
    "        mol, saliency_map_2, \n",
    "        f'../output/saliency/integrated/RIKEN_{pair}-{i}-{epoch}.png')\n",
    "\n",
    "    pair += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 2678 calls to <function GCNModel.call at 0x7f7c4842c830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "pair = 0\n",
    "\n",
    "for example_1, example_2 in zip(hilic_data, rplc_data):\n",
    "\n",
    "    (A, H, y, mol, i) = example_1\n",
    "\n",
    "    saliency_map = vanilla_atom_saliency(gcn_model_hilic, A, H, y)\n",
    "    #mol = transform_ops.mol_from_string(s)\n",
    "    draw_atom_saliency_on_mol(\n",
    "        mol, saliency_map, f'../output/saliency/vanilla/Fiehn-HILIC_{pair}-{i}.png')\n",
    "\n",
    "    (A, H, y, mol, i) = example_2\n",
    "\n",
    "    saliency_map = vanilla_atom_saliency(gcn_model_rplc, A, H, y)\n",
    "    #mol = transform_ops.mol_from_string(s)\n",
    "    draw_atom_saliency_on_mol(\n",
    "        mol, saliency_map, f'../output/saliency/vanilla/RIKEN_{pair}-{i}.png')\n",
    "\n",
    "    pair += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-35a51ab75bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0msaliency_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintegrated_atom_saliency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_model_rplc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#mol = transform_ops.mol_from_string(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     draw_atom_saliency_on_mol(\n",
      "\u001b[0;32m<ipython-input-4-cd4dff36938c>\u001b[0m in \u001b[0;36mintegrated_atom_saliency\u001b[0;34m(gcn_model, A, H, y, m_steps)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhuber_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mgradients_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradients_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my-rdkit-env/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my-rdkit-env/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/my-rdkit-env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backward_function_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1282\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m       return backward._call_flat(  # pylint: disable=protected-access\n\u001b[0;32m-> 1284\u001b[0;31m           processed_args, remapped_captures)\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_backward_function_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecorded_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my-rdkit-env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my-rdkit-env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/my-rdkit-env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pair = 0\n",
    "\n",
    "for example_1, example_2 in zip(hilic_data, rplc_data):\n",
    "\n",
    "    (A, H, y, mol, i) = example_1\n",
    "\n",
    "    saliency_map = integrated_atom_saliency(gcn_model_hilic, A, H, y)\n",
    "    #mol = transform_ops.mol_from_string(s)\n",
    "    draw_atom_saliency_on_mol(\n",
    "        mol, saliency_map, f'../output/saliency/integrated/Fiehn-HILIC_{pair}-{i}.png')\n",
    "\n",
    "    (A, H, y, mol, i) = example_2\n",
    "\n",
    "    saliency_map = integrated_atom_saliency(gcn_model_rplc, A, H, y)\n",
    "    #mol = transform_ops.mol_from_string(s)\n",
    "    draw_atom_saliency_on_mol(\n",
    "        mol, saliency_map, f'../output/saliency/integrated/RIKEN_{pair}-{i}.png')\n",
    "\n",
    "    pair += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair = 0\n",
    "\n",
    "# for example_1, example_2 in zip(hilic_data, rplc_data):\n",
    "\n",
    "#     (A, H, y, s, i) = example_1\n",
    "\n",
    "#     saliency_map = smoothgrad_atom_saliency(gcn_model_hilic, A, H, y, noise=0.1)\n",
    "#     mol = transform_ops.mol_from_string(s)\n",
    "#     draw_atom_saliency_on_mol(\n",
    "#         mol, saliency_map, f'../output/saliency/smoothgrad/Fiehn-HILIC_{pair}-{i}.png')\n",
    "\n",
    "#     (A, H, y, s, i) = example_2\n",
    "\n",
    "#     saliency_map = smoothgrad_atom_saliency(gcn_model_rplc, A, H, y, noise=0.1)\n",
    "#     mol = transform_ops.mol_from_string(s)\n",
    "#     draw_atom_saliency_on_mol(\n",
    "#         mol, saliency_map, f'../output/saliency/smoothgrad/RIKEN_{pair}-{i}.png')\n",
    "\n",
    "#     pair += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "\n",
    "\n",
    "font = ImageFont.truetype(\n",
    "    \"/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf\", \n",
    "    34)\n",
    "\n",
    "\n",
    "\n",
    "for pair in range(74):\n",
    "\n",
    "    vanilla_rplc = glob.glob(f'../output/saliency/vanilla/RIKEN_{pair}-*')[0]\n",
    "    vanilla_hilic = glob.glob(f'../output/saliency/vanilla/Fiehn-HILIC_{pair}-*')[0]\n",
    "    integrated_rplc = glob.glob(f'../output/saliency/integrated/RIKEN_{pair}-*')[0]\n",
    "    integrated_hilic = glob.glob(f'../output/saliency/integrated/Fiehn-HILIC_{pair}-*')[0]\n",
    "    \n",
    "    idx1 = vanilla_rplc.split('-')[-2].split('.')[0]\n",
    "    idx2 = vanilla_hilic.split('-')[-2].split('.')[0]\n",
    "    \n",
    "    pair_vanilla_rplc = np.array(Image.open(vanilla_rplc))\n",
    "    pair_vanilla_hilic = np.array(Image.open(vanilla_hilic))\n",
    "    \n",
    "    pair_integrated_rplc = np.array(Image.open(integrated_rplc))\n",
    "    pair_integrated_hilic = np.array(Image.open(integrated_hilic))\n",
    "    \n",
    "\n",
    "    vanilla = np.concatenate([pair_vanilla_rplc, pair_vanilla_hilic], axis=1)\n",
    "    intgrad = np.concatenate([pair_integrated_rplc, pair_integrated_hilic], axis=1)\n",
    "\n",
    "    img = np.concatenate([vanilla[:-100], intgrad], axis=0)\n",
    "\n",
    "\n",
    "    img = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    draw.text((350,  0), \n",
    "              f\"RIKEN(RP)\",    \n",
    "              (0,0,0), \n",
    "              font=font)\n",
    "    draw.text((1350, 0), \n",
    "              f\"Fiehn(HILIC)\", \n",
    "              (0,0,0), \n",
    "              font=font)\n",
    "\n",
    "    draw.text((350,  100), \n",
    "              f\"Vanilla\",    \n",
    "              (0,0,0), \n",
    "              font=font)\n",
    "    draw.text((1350, 100), \n",
    "              f\"Vanilla\", \n",
    "              (0,0,0), \n",
    "              font=font)\n",
    "\n",
    "    \n",
    "    draw.text((350,  900), \n",
    "              f\"RIKEN(RP)\",    \n",
    "              (0,0,0), \n",
    "              font=font)\n",
    "    draw.text((1350, 900), \n",
    "              f\"Fiehn(HILIC)\", \n",
    "              (0,0,0), \n",
    "              font=font)\n",
    "    \n",
    "    draw.text((350,  1000), \n",
    "              f\"Integrated\",    \n",
    "              (0,0,0), \n",
    "              font=font)\n",
    "    draw.text((1350, 1000), \n",
    "              f\"Integrated\", \n",
    "              (0,0,0), \n",
    "              font=font)\n",
    "    \n",
    "    img.save(f\"../output/saliency/combined/combined_{pair}-{idx1}-{idx2}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cb062f3c12496da60f85a6ea6fbcb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hilic_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e6702e10e370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m     )\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mexample_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhilic_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrplc_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hilic_data' is not defined"
     ]
    }
   ],
   "source": [
    "# FOR GIFS\n",
    "\n",
    "\n",
    "# def compute_atom_saliency(model, A, H, y):\n",
    "\n",
    "#     # remove potential padding\n",
    "#     keep_idx = np.where(A.sum(axis=1) != 0)[0]\n",
    "#     H = tf.convert_to_tensor(H[keep_idx])[tf.newaxis]\n",
    "#     A = tf.convert_to_tensor(A[keep_idx][:, keep_idx])[tf.newaxis]\n",
    "#     y = tf.convert_to_tensor(y)[tf.newaxis]\n",
    "\n",
    "#     with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "#         tape.watch(H)\n",
    "#         y_pred = model([A, H])\n",
    "#         loss = tf.compat.v1.losses.huber_loss(y, y_pred)\n",
    "\n",
    "#     gradients = tape.gradient(loss, H)\n",
    "#     gradients = tf.abs(gradients)\n",
    "#     return tf.reduce_sum(gradients, axis=1).numpy()\n",
    "\n",
    "# def draw_atom_saliency_on_mol(mol, saliency, path, size=(1000, 1000)):\n",
    "\n",
    "#     if not os.path.isdir('/'.join(path.split('/')[:-1])):\n",
    "#         os.makedirs('/'.join(path.split('/')[:-1]))\n",
    "\n",
    "#     drawer = Draw.MolDraw2DCairo(*size)\n",
    "#     drawer.drawOptions().bondLineWidth = 3\n",
    "\n",
    "#     saliency = saliency / saliency.max()\n",
    "\n",
    "#     Draw.SimilarityMaps.GetSimilarityMapFromWeights(\n",
    "#         mol=mol,\n",
    "#         weights=[float(s) for s in saliency],\n",
    "#         size=size,\n",
    "#         coordScale=1.0,\n",
    "#         colors='g',\n",
    "#         alpha=0.4,\n",
    "#         contourLines=10,\n",
    "#         draw2d=drawer);\n",
    "\n",
    "#     drawer.FinishDrawing()\n",
    "#     drawer.WriteDrawingText(path)\n",
    "\n",
    "\n",
    "# batch_size = 32\n",
    "# num_epochs = 200\n",
    "\n",
    "# # Train on all data\n",
    "# train_dataset = GCNDataset(\n",
    "#     [f'../input/tfrecords/Fiehn_HILIC/train.tfrec',\n",
    "#      f'../input/tfrecords/Fiehn_HILIC/valid.tfrec',\n",
    "#      f'../input/tfrecords/Fiehn_HILIC/test_1.tfrec',\n",
    "#      f'../input/tfrecords/Fiehn_HILIC/test_2.tfrec'], \n",
    "#     batch_size, training=True)\n",
    "\n",
    "# # build model (with default hyper-parameters)\n",
    "# gcn_model = GCNModel()\n",
    "\n",
    "# # fit model for {num_epochs} with a batch_size of {batch_size}\n",
    "# pair = 0\n",
    "# for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "#     gcn_model.fit(\n",
    "#         train_dataset.get_iterator(), \n",
    "#         epochs=1, verbose=0\n",
    "#     )\n",
    "    \n",
    "#     for example_1, example_2 in zip(hilic_data, rplc_data):\n",
    "        \n",
    "#         (A, H, y, s, i) = example_1\n",
    "        \n",
    "#         saliency_map = compute_atom_saliency_int_grad(gcn_model, A, H, y)\n",
    "#         mol = transform_ops.mol_from_string(s)\n",
    "#         draw_atom_saliency_on_mol(\n",
    "#             mol, saliency_map, f'../output/saliency/{pair}/Fiehn_HILIC/{pair}-{i}-{epoch}_Fiehn_HILIC.png')\n",
    "        \n",
    "#         (A, H, y, s, i) = example_2\n",
    "\n",
    "#         saliency_map = compute_atom_saliency_int_grad(gcn_model, A, H, y)\n",
    "#         mol = transform_ops.mol_from_string(s)\n",
    "#         draw_atom_saliency_on_mol(\n",
    "#             mol, saliency_map, f'../output/saliency/{pair}/RIKEN/{pair}-{i}-{epoch}_RIKEN.png')\n",
    "        \n",
    "#         pair += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define function for serving trained model later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serve_model(model):\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        [tf.TensorSpec([None, None], dtype='float32', name='A'),\n",
    "         tf.TensorSpec([None, None], dtype='float32', name='H')]\n",
    "    ])\n",
    "    def serve(inputs):\n",
    "        return {\n",
    "            'prediction': model.call(\n",
    "                inputs=[inputs[0][tf.newaxis], inputs[1][tf.newaxis]],\n",
    "                training=False\n",
    "            )\n",
    "        }\n",
    "    return serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train on Fiehn HILIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 000 : lr 0.001000 : loss 1.517 : : 100%|██████████| 44/44 [00:01<00:00, 29.10it/s]\n",
      "epoch 001 : lr 0.001000 : loss 1.231 : : 100%|██████████| 44/44 [00:00<00:00, 91.38it/s]\n",
      "epoch 002 : lr 0.001000 : loss 1.113 : : 100%|██████████| 44/44 [00:00<00:00, 90.88it/s]\n",
      "epoch 003 : lr 0.001000 : loss 1.027 : : 100%|██████████| 44/44 [00:00<00:00, 89.16it/s]\n",
      "epoch 004 : lr 0.001000 : loss 0.967 : : 100%|██████████| 44/44 [00:00<00:00, 86.21it/s]\n",
      "epoch 005 : lr 0.001000 : loss 0.936 : : 100%|██████████| 44/44 [00:00<00:00, 89.77it/s]\n",
      "epoch 006 : lr 0.001000 : loss 0.904 : : 100%|██████████| 44/44 [00:00<00:00, 89.85it/s]\n",
      "epoch 007 : lr 0.001000 : loss 0.870 : : 100%|██████████| 44/44 [00:00<00:00, 89.89it/s]\n",
      "epoch 008 : lr 0.001000 : loss 0.840 : : 100%|██████████| 44/44 [00:00<00:00, 89.19it/s]\n",
      "epoch 009 : lr 0.001000 : loss 0.808 : : 100%|██████████| 44/44 [00:00<00:00, 86.07it/s]\n",
      "epoch 010 : lr 0.001000 : loss 0.779 : : 100%|██████████| 44/44 [00:00<00:00, 91.39it/s]\n",
      "epoch 011 : lr 0.001000 : loss 0.755 : : 100%|██████████| 44/44 [00:00<00:00, 89.88it/s]\n",
      "epoch 012 : lr 0.001000 : loss 0.732 : : 100%|██████████| 44/44 [00:00<00:00, 90.42it/s]\n",
      "epoch 013 : lr 0.001000 : loss 0.713 : : 100%|██████████| 44/44 [00:00<00:00, 89.92it/s]\n",
      "epoch 014 : lr 0.001000 : loss 0.693 : : 100%|██████████| 44/44 [00:00<00:00, 89.12it/s]\n",
      "epoch 015 : lr 0.001000 : loss 0.674 : : 100%|██████████| 44/44 [00:00<00:00, 88.33it/s]\n",
      "epoch 016 : lr 0.001000 : loss 0.660 : : 100%|██████████| 44/44 [00:00<00:00, 90.24it/s]\n",
      "epoch 017 : lr 0.001000 : loss 0.645 : : 100%|██████████| 44/44 [00:00<00:00, 90.54it/s]\n",
      "epoch 018 : lr 0.001000 : loss 0.629 : : 100%|██████████| 44/44 [00:00<00:00, 91.21it/s]\n",
      "epoch 019 : lr 0.001000 : loss 0.615 : : 100%|██████████| 44/44 [00:00<00:00, 90.97it/s]\n",
      "epoch 020 : lr 0.001000 : loss 0.602 : : 100%|██████████| 44/44 [00:00<00:00, 90.67it/s]\n",
      "epoch 021 : lr 0.001000 : loss 0.589 : : 100%|██████████| 44/44 [00:00<00:00, 88.26it/s]\n",
      "epoch 022 : lr 0.001000 : loss 0.576 : : 100%|██████████| 44/44 [00:00<00:00, 90.40it/s]\n",
      "epoch 023 : lr 0.001000 : loss 0.565 : : 100%|██████████| 44/44 [00:00<00:00, 89.61it/s]\n",
      "epoch 024 : lr 0.001000 : loss 0.555 : : 100%|██████████| 44/44 [00:00<00:00, 89.36it/s]\n",
      "epoch 025 : lr 0.001000 : loss 0.548 : : 100%|██████████| 44/44 [00:00<00:00, 89.21it/s]\n",
      "epoch 026 : lr 0.001000 : loss 0.538 : : 100%|██████████| 44/44 [00:00<00:00, 90.78it/s]\n",
      "epoch 027 : lr 0.001000 : loss 0.529 : : 100%|██████████| 44/44 [00:00<00:00, 89.39it/s]\n",
      "epoch 028 : lr 0.001000 : loss 0.520 : : 100%|██████████| 44/44 [00:00<00:00, 90.77it/s]\n",
      "epoch 029 : lr 0.001000 : loss 0.512 : : 100%|██████████| 44/44 [00:00<00:00, 91.70it/s]\n",
      "epoch 030 : lr 0.001000 : loss 0.504 : : 100%|██████████| 44/44 [00:00<00:00, 90.35it/s]\n",
      "epoch 031 : lr 0.001000 : loss 0.497 : : 100%|██████████| 44/44 [00:00<00:00, 90.22it/s]\n",
      "epoch 032 : lr 0.001000 : loss 0.489 : : 100%|██████████| 44/44 [00:00<00:00, 91.17it/s]\n",
      "epoch 033 : lr 0.001000 : loss 0.482 : : 100%|██████████| 44/44 [00:00<00:00, 88.57it/s]\n",
      "epoch 034 : lr 0.001000 : loss 0.475 : : 100%|██████████| 44/44 [00:00<00:00, 89.55it/s]\n",
      "epoch 035 : lr 0.001000 : loss 0.468 : : 100%|██████████| 44/44 [00:00<00:00, 86.21it/s]\n",
      "epoch 036 : lr 0.001000 : loss 0.461 : : 100%|██████████| 44/44 [00:00<00:00, 84.44it/s]\n",
      "epoch 037 : lr 0.001000 : loss 0.455 : : 100%|██████████| 44/44 [00:00<00:00, 85.92it/s]\n",
      "epoch 038 : lr 0.001000 : loss 0.449 : : 100%|██████████| 44/44 [00:00<00:00, 90.54it/s]\n",
      "epoch 039 : lr 0.001000 : loss 0.443 : : 100%|██████████| 44/44 [00:00<00:00, 86.56it/s]\n",
      "epoch 040 : lr 0.001000 : loss 0.438 : : 100%|██████████| 44/44 [00:00<00:00, 89.19it/s]\n",
      "epoch 041 : lr 0.001000 : loss 0.432 : : 100%|██████████| 44/44 [00:00<00:00, 91.92it/s]\n",
      "epoch 042 : lr 0.001000 : loss 0.428 : : 100%|██████████| 44/44 [00:00<00:00, 89.72it/s]\n",
      "epoch 043 : lr 0.001000 : loss 0.423 : : 100%|██████████| 44/44 [00:00<00:00, 89.57it/s]\n",
      "epoch 044 : lr 0.001000 : loss 0.417 : : 100%|██████████| 44/44 [00:00<00:00, 90.72it/s]\n",
      "epoch 045 : lr 0.001000 : loss 0.412 : : 100%|██████████| 44/44 [00:00<00:00, 87.60it/s]\n",
      "epoch 046 : lr 0.001000 : loss 0.406 : : 100%|██████████| 44/44 [00:00<00:00, 92.14it/s]\n",
      "epoch 047 : lr 0.001000 : loss 0.402 : : 100%|██████████| 44/44 [00:00<00:00, 90.94it/s]\n",
      "epoch 048 : lr 0.001000 : loss 0.397 : : 100%|██████████| 44/44 [00:00<00:00, 88.18it/s]\n",
      "epoch 049 : lr 0.001000 : loss 0.392 : : 100%|██████████| 44/44 [00:00<00:00, 90.45it/s]\n",
      "epoch 050 : lr 0.001000 : loss 0.387 : : 100%|██████████| 44/44 [00:00<00:00, 89.82it/s]\n",
      "epoch 051 : lr 0.001000 : loss 0.383 : : 100%|██████████| 44/44 [00:00<00:00, 90.17it/s]\n",
      "epoch 052 : lr 0.001000 : loss 0.378 : : 100%|██████████| 44/44 [00:00<00:00, 89.81it/s]\n",
      "epoch 053 : lr 0.001000 : loss 0.373 : : 100%|██████████| 44/44 [00:00<00:00, 90.90it/s]\n",
      "epoch 054 : lr 0.001000 : loss 0.369 : : 100%|██████████| 44/44 [00:00<00:00, 89.60it/s]\n",
      "epoch 055 : lr 0.001000 : loss 0.365 : : 100%|██████████| 44/44 [00:00<00:00, 91.49it/s]\n",
      "epoch 056 : lr 0.001000 : loss 0.361 : : 100%|██████████| 44/44 [00:00<00:00, 92.06it/s]\n",
      "epoch 057 : lr 0.001000 : loss 0.357 : : 100%|██████████| 44/44 [00:00<00:00, 88.88it/s]\n",
      "epoch 058 : lr 0.001000 : loss 0.353 : : 100%|██████████| 44/44 [00:00<00:00, 89.08it/s]\n",
      "epoch 059 : lr 0.001000 : loss 0.349 : : 100%|██████████| 44/44 [00:00<00:00, 90.48it/s]\n",
      "epoch 060 : lr 0.001000 : loss 0.345 : : 100%|██████████| 44/44 [00:00<00:00, 89.72it/s]\n",
      "epoch 061 : lr 0.001000 : loss 0.342 : : 100%|██████████| 44/44 [00:00<00:00, 90.11it/s]\n",
      "epoch 062 : lr 0.001000 : loss 0.339 : : 100%|██████████| 44/44 [00:00<00:00, 90.41it/s]\n",
      "epoch 063 : lr 0.001000 : loss 0.335 : : 100%|██████████| 44/44 [00:00<00:00, 88.79it/s]\n",
      "epoch 064 : lr 0.001000 : loss 0.332 : : 100%|██████████| 44/44 [00:00<00:00, 90.27it/s]\n",
      "epoch 065 : lr 0.001000 : loss 0.329 : : 100%|██████████| 44/44 [00:00<00:00, 89.78it/s]\n",
      "epoch 066 : lr 0.001000 : loss 0.326 : : 100%|██████████| 44/44 [00:00<00:00, 89.90it/s]\n",
      "epoch 067 : lr 0.001000 : loss 0.322 : : 100%|██████████| 44/44 [00:00<00:00, 90.23it/s]\n",
      "epoch 068 : lr 0.001000 : loss 0.319 : : 100%|██████████| 44/44 [00:00<00:00, 90.29it/s]\n",
      "epoch 069 : lr 0.001000 : loss 0.316 : : 100%|██████████| 44/44 [00:00<00:00, 86.43it/s]\n",
      "epoch 070 : lr 0.001000 : loss 0.313 : : 100%|██████████| 44/44 [00:00<00:00, 91.83it/s]\n",
      "epoch 071 : lr 0.001000 : loss 0.310 : : 100%|██████████| 44/44 [00:00<00:00, 87.88it/s]\n",
      "epoch 072 : lr 0.001000 : loss 0.307 : : 100%|██████████| 44/44 [00:00<00:00, 89.26it/s]\n",
      "epoch 073 : lr 0.001000 : loss 0.304 : : 100%|██████████| 44/44 [00:00<00:00, 84.31it/s]\n",
      "epoch 074 : lr 0.001000 : loss 0.301 : : 100%|██████████| 44/44 [00:00<00:00, 87.79it/s]\n",
      "epoch 075 : lr 0.001000 : loss 0.298 : : 100%|██████████| 44/44 [00:00<00:00, 90.87it/s]\n",
      "epoch 076 : lr 0.001000 : loss 0.296 : : 100%|██████████| 44/44 [00:00<00:00, 85.23it/s]\n",
      "epoch 077 : lr 0.001000 : loss 0.293 : : 100%|██████████| 44/44 [00:00<00:00, 84.48it/s]\n",
      "epoch 078 : lr 0.001000 : loss 0.290 : : 100%|██████████| 44/44 [00:00<00:00, 85.46it/s]\n",
      "epoch 079 : lr 0.001000 : loss 0.288 : : 100%|██████████| 44/44 [00:00<00:00, 85.75it/s]\n",
      "epoch 080 : lr 0.001000 : loss 0.286 : : 100%|██████████| 44/44 [00:00<00:00, 83.54it/s]\n",
      "epoch 081 : lr 0.001000 : loss 0.284 : : 100%|██████████| 44/44 [00:00<00:00, 87.32it/s]\n",
      "epoch 082 : lr 0.001000 : loss 0.282 : : 100%|██████████| 44/44 [00:00<00:00, 90.04it/s]\n",
      "epoch 083 : lr 0.001000 : loss 0.279 : : 100%|██████████| 44/44 [00:00<00:00, 90.24it/s]\n",
      "epoch 084 : lr 0.001000 : loss 0.277 : : 100%|██████████| 44/44 [00:00<00:00, 91.11it/s]\n",
      "epoch 085 : lr 0.001000 : loss 0.274 : : 100%|██████████| 44/44 [00:00<00:00, 88.11it/s]\n",
      "epoch 086 : lr 0.001000 : loss 0.272 : : 100%|██████████| 44/44 [00:00<00:00, 90.88it/s]\n",
      "epoch 087 : lr 0.001000 : loss 0.270 : : 100%|██████████| 44/44 [00:00<00:00, 88.45it/s]\n",
      "epoch 088 : lr 0.001000 : loss 0.268 : : 100%|██████████| 44/44 [00:00<00:00, 87.96it/s]\n",
      "epoch 089 : lr 0.001000 : loss 0.265 : : 100%|██████████| 44/44 [00:00<00:00, 89.56it/s]\n",
      "epoch 090 : lr 0.001000 : loss 0.263 : : 100%|██████████| 44/44 [00:00<00:00, 89.85it/s]\n",
      "epoch 091 : lr 0.001000 : loss 0.261 : : 100%|██████████| 44/44 [00:00<00:00, 89.99it/s]\n",
      "epoch 092 : lr 0.001000 : loss 0.259 : : 100%|██████████| 44/44 [00:00<00:00, 91.40it/s]\n",
      "epoch 093 : lr 0.001000 : loss 0.257 : : 100%|██████████| 44/44 [00:00<00:00, 90.71it/s]\n",
      "epoch 094 : lr 0.001000 : loss 0.255 : : 100%|██████████| 44/44 [00:00<00:00, 91.17it/s]\n",
      "epoch 095 : lr 0.001000 : loss 0.253 : : 100%|██████████| 44/44 [00:00<00:00, 90.47it/s]\n",
      "epoch 096 : lr 0.001000 : loss 0.251 : : 100%|██████████| 44/44 [00:00<00:00, 89.67it/s]\n",
      "epoch 097 : lr 0.001000 : loss 0.249 : : 100%|██████████| 44/44 [00:00<00:00, 89.95it/s]\n",
      "epoch 098 : lr 0.001000 : loss 0.247 : : 100%|██████████| 44/44 [00:00<00:00, 87.91it/s]\n",
      "epoch 099 : lr 0.001000 : loss 0.245 : : 100%|██████████| 44/44 [00:00<00:00, 91.42it/s]\n",
      "epoch 100 : lr 0.001000 : loss 0.244 : : 100%|██████████| 44/44 [00:00<00:00, 92.83it/s]\n",
      "epoch 101 : lr 0.001000 : loss 0.242 : : 100%|██████████| 44/44 [00:00<00:00, 92.90it/s]\n",
      "epoch 102 : lr 0.001000 : loss 0.240 : : 100%|██████████| 44/44 [00:00<00:00, 86.49it/s]\n",
      "epoch 103 : lr 0.001000 : loss 0.239 : : 100%|██████████| 44/44 [00:00<00:00, 92.69it/s]\n",
      "epoch 104 : lr 0.001000 : loss 0.237 : : 100%|██████████| 44/44 [00:00<00:00, 91.76it/s]\n",
      "epoch 105 : lr 0.001000 : loss 0.235 : : 100%|██████████| 44/44 [00:00<00:00, 91.37it/s]\n",
      "epoch 106 : lr 0.001000 : loss 0.233 : : 100%|██████████| 44/44 [00:00<00:00, 85.70it/s]\n",
      "epoch 107 : lr 0.001000 : loss 0.232 : : 100%|██████████| 44/44 [00:00<00:00, 91.67it/s]\n",
      "epoch 108 : lr 0.001000 : loss 0.230 : : 100%|██████████| 44/44 [00:00<00:00, 91.34it/s]\n",
      "epoch 109 : lr 0.001000 : loss 0.228 : : 100%|██████████| 44/44 [00:00<00:00, 90.23it/s]\n",
      "epoch 110 : lr 0.001000 : loss 0.227 : : 100%|██████████| 44/44 [00:00<00:00, 90.98it/s]\n",
      "epoch 111 : lr 0.001000 : loss 0.225 : : 100%|██████████| 44/44 [00:00<00:00, 92.14it/s]\n",
      "epoch 112 : lr 0.001000 : loss 0.224 : : 100%|██████████| 44/44 [00:00<00:00, 91.79it/s]\n",
      "epoch 113 : lr 0.001000 : loss 0.222 : : 100%|██████████| 44/44 [00:00<00:00, 90.15it/s]\n",
      "epoch 114 : lr 0.001000 : loss 0.221 : : 100%|██████████| 44/44 [00:00<00:00, 91.09it/s]\n",
      "epoch 115 : lr 0.001000 : loss 0.220 : : 100%|██████████| 44/44 [00:00<00:00, 90.86it/s]\n",
      "epoch 116 : lr 0.001000 : loss 0.219 : : 100%|██████████| 44/44 [00:00<00:00, 91.86it/s]\n",
      "epoch 117 : lr 0.001000 : loss 0.217 : : 100%|██████████| 44/44 [00:00<00:00, 91.84it/s]\n",
      "epoch 118 : lr 0.001000 : loss 0.216 : : 100%|██████████| 44/44 [00:00<00:00, 90.62it/s]\n",
      "epoch 119 : lr 0.001000 : loss 0.214 : : 100%|██████████| 44/44 [00:00<00:00, 90.30it/s]\n",
      "epoch 120 : lr 0.001000 : loss 0.213 : : 100%|██████████| 44/44 [00:00<00:00, 90.19it/s]\n",
      "epoch 121 : lr 0.001000 : loss 0.212 : : 100%|██████████| 44/44 [00:00<00:00, 89.92it/s]\n",
      "epoch 122 : lr 0.001000 : loss 0.210 : : 100%|██████████| 44/44 [00:00<00:00, 90.41it/s]\n",
      "epoch 123 : lr 0.001000 : loss 0.209 : : 100%|██████████| 44/44 [00:00<00:00, 90.96it/s]\n",
      "epoch 124 : lr 0.001000 : loss 0.207 : : 100%|██████████| 44/44 [00:00<00:00, 92.56it/s]\n",
      "epoch 125 : lr 0.001000 : loss 0.206 : : 100%|██████████| 44/44 [00:00<00:00, 90.39it/s]\n",
      "epoch 126 : lr 0.001000 : loss 0.205 : : 100%|██████████| 44/44 [00:00<00:00, 91.17it/s]\n",
      "epoch 127 : lr 0.001000 : loss 0.204 : : 100%|██████████| 44/44 [00:00<00:00, 87.38it/s]\n",
      "epoch 128 : lr 0.001000 : loss 0.202 : : 100%|██████████| 44/44 [00:00<00:00, 92.62it/s]\n",
      "epoch 129 : lr 0.001000 : loss 0.201 : : 100%|██████████| 44/44 [00:00<00:00, 90.59it/s]\n",
      "epoch 130 : lr 0.001000 : loss 0.200 : : 100%|██████████| 44/44 [00:00<00:00, 92.42it/s]\n",
      "epoch 131 : lr 0.001000 : loss 0.199 : : 100%|██████████| 44/44 [00:00<00:00, 86.43it/s]\n",
      "epoch 132 : lr 0.001000 : loss 0.198 : : 100%|██████████| 44/44 [00:00<00:00, 92.78it/s]\n",
      "epoch 133 : lr 0.001000 : loss 0.196 : : 100%|██████████| 44/44 [00:00<00:00, 91.56it/s]\n",
      "epoch 134 : lr 0.001000 : loss 0.195 : : 100%|██████████| 44/44 [00:00<00:00, 90.23it/s]\n",
      "epoch 135 : lr 0.001000 : loss 0.194 : : 100%|██████████| 44/44 [00:00<00:00, 91.65it/s]\n",
      "epoch 136 : lr 0.001000 : loss 0.193 : : 100%|██████████| 44/44 [00:00<00:00, 88.89it/s]\n",
      "epoch 137 : lr 0.001000 : loss 0.192 : : 100%|██████████| 44/44 [00:00<00:00, 89.96it/s]\n",
      "epoch 138 : lr 0.001000 : loss 0.191 : : 100%|██████████| 44/44 [00:00<00:00, 90.47it/s]\n",
      "epoch 139 : lr 0.001000 : loss 0.190 : : 100%|██████████| 44/44 [00:00<00:00, 86.34it/s]\n",
      "epoch 140 : lr 0.001000 : loss 0.189 : : 100%|██████████| 44/44 [00:00<00:00, 88.27it/s]\n",
      "epoch 141 : lr 0.001000 : loss 0.188 : : 100%|██████████| 44/44 [00:00<00:00, 89.21it/s]\n",
      "epoch 142 : lr 0.001000 : loss 0.187 : : 100%|██████████| 44/44 [00:00<00:00, 89.00it/s]\n",
      "epoch 143 : lr 0.001000 : loss 0.186 : : 100%|██████████| 44/44 [00:00<00:00, 86.31it/s]\n",
      "epoch 144 : lr 0.001000 : loss 0.185 : : 100%|██████████| 44/44 [00:00<00:00, 87.80it/s]\n",
      "epoch 145 : lr 0.001000 : loss 0.184 : : 100%|██████████| 44/44 [00:00<00:00, 85.21it/s]\n",
      "epoch 146 : lr 0.001000 : loss 0.183 : : 100%|██████████| 44/44 [00:00<00:00, 76.27it/s]\n",
      "epoch 147 : lr 0.001000 : loss 0.182 : : 100%|██████████| 44/44 [00:00<00:00, 88.42it/s]\n",
      "epoch 148 : lr 0.001000 : loss 0.181 : : 100%|██████████| 44/44 [00:00<00:00, 87.66it/s]\n",
      "epoch 149 : lr 0.001000 : loss 0.180 : : 100%|██████████| 44/44 [00:00<00:00, 88.22it/s]\n",
      "epoch 150 : lr 0.001000 : loss 0.179 : : 100%|██████████| 44/44 [00:00<00:00, 89.87it/s]\n",
      "epoch 151 : lr 0.001000 : loss 0.178 : : 100%|██████████| 44/44 [00:00<00:00, 88.20it/s]\n",
      "epoch 152 : lr 0.001000 : loss 0.177 : : 100%|██████████| 44/44 [00:00<00:00, 83.08it/s]\n",
      "epoch 153 : lr 0.001000 : loss 0.176 : : 100%|██████████| 44/44 [00:00<00:00, 86.65it/s]\n",
      "epoch 154 : lr 0.001000 : loss 0.175 : : 100%|██████████| 44/44 [00:00<00:00, 87.40it/s]\n",
      "epoch 155 : lr 0.001000 : loss 0.174 : : 100%|██████████| 44/44 [00:00<00:00, 86.84it/s]\n",
      "epoch 156 : lr 0.001000 : loss 0.173 : : 100%|██████████| 44/44 [00:00<00:00, 87.55it/s]\n",
      "epoch 157 : lr 0.001000 : loss 0.173 : : 100%|██████████| 44/44 [00:00<00:00, 83.95it/s]\n",
      "epoch 158 : lr 0.001000 : loss 0.172 : : 100%|██████████| 44/44 [00:00<00:00, 88.24it/s]\n",
      "epoch 159 : lr 0.001000 : loss 0.171 : : 100%|██████████| 44/44 [00:00<00:00, 89.78it/s]\n",
      "epoch 160 : lr 0.001000 : loss 0.170 : : 100%|██████████| 44/44 [00:00<00:00, 85.97it/s]\n",
      "epoch 161 : lr 0.000100 : loss 0.169 : : 100%|██████████| 44/44 [00:00<00:00, 81.85it/s]\n",
      "epoch 162 : lr 0.000100 : loss 0.168 : : 100%|██████████| 44/44 [00:00<00:00, 82.09it/s]\n",
      "epoch 163 : lr 0.000100 : loss 0.167 : : 100%|██████████| 44/44 [00:00<00:00, 87.71it/s]\n",
      "epoch 164 : lr 0.000100 : loss 0.166 : : 100%|██████████| 44/44 [00:00<00:00, 89.15it/s]\n",
      "epoch 165 : lr 0.000100 : loss 0.166 : : 100%|██████████| 44/44 [00:00<00:00, 89.05it/s]\n",
      "epoch 166 : lr 0.000100 : loss 0.165 : : 100%|██████████| 44/44 [00:00<00:00, 83.82it/s]\n",
      "epoch 167 : lr 0.000100 : loss 0.164 : : 100%|██████████| 44/44 [00:00<00:00, 89.74it/s]\n",
      "epoch 168 : lr 0.000100 : loss 0.163 : : 100%|██████████| 44/44 [00:00<00:00, 88.07it/s]\n",
      "epoch 169 : lr 0.000100 : loss 0.162 : : 100%|██████████| 44/44 [00:00<00:00, 88.36it/s]\n",
      "epoch 170 : lr 0.000100 : loss 0.161 : : 100%|██████████| 44/44 [00:00<00:00, 87.57it/s]\n",
      "epoch 171 : lr 0.000100 : loss 0.160 : : 100%|██████████| 44/44 [00:00<00:00, 89.47it/s]\n",
      "epoch 172 : lr 0.000100 : loss 0.159 : : 100%|██████████| 44/44 [00:00<00:00, 90.01it/s]\n",
      "epoch 173 : lr 0.000100 : loss 0.158 : : 100%|██████████| 44/44 [00:00<00:00, 86.45it/s]\n",
      "epoch 174 : lr 0.000100 : loss 0.158 : : 100%|██████████| 44/44 [00:00<00:00, 88.91it/s]\n",
      "epoch 175 : lr 0.000100 : loss 0.157 : : 100%|██████████| 44/44 [00:00<00:00, 86.32it/s]\n",
      "epoch 176 : lr 0.000100 : loss 0.156 : : 100%|██████████| 44/44 [00:00<00:00, 89.30it/s]\n",
      "epoch 177 : lr 0.000100 : loss 0.155 : : 100%|██████████| 44/44 [00:00<00:00, 83.63it/s]\n",
      "epoch 178 : lr 0.000100 : loss 0.154 : : 100%|██████████| 44/44 [00:00<00:00, 86.20it/s]\n",
      "epoch 179 : lr 0.000100 : loss 0.153 : : 100%|██████████| 44/44 [00:00<00:00, 90.24it/s]\n",
      "epoch 180 : lr 0.000100 : loss 0.153 : : 100%|██████████| 44/44 [00:00<00:00, 88.80it/s]\n",
      "epoch 181 : lr 0.000100 : loss 0.152 : : 100%|██████████| 44/44 [00:00<00:00, 89.09it/s]\n",
      "epoch 182 : lr 0.000100 : loss 0.151 : : 100%|██████████| 44/44 [00:00<00:00, 87.98it/s]\n",
      "epoch 183 : lr 0.000100 : loss 0.150 : : 100%|██████████| 44/44 [00:00<00:00, 89.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 184 : lr 0.000100 : loss 0.150 : : 100%|██████████| 44/44 [00:00<00:00, 89.64it/s]\n",
      "epoch 185 : lr 0.000100 : loss 0.149 : : 100%|██████████| 44/44 [00:00<00:00, 89.71it/s]\n",
      "epoch 186 : lr 0.000100 : loss 0.148 : : 100%|██████████| 44/44 [00:00<00:00, 86.22it/s]\n",
      "epoch 187 : lr 0.000100 : loss 0.147 : : 100%|██████████| 44/44 [00:00<00:00, 88.15it/s]\n",
      "epoch 188 : lr 0.000100 : loss 0.147 : : 100%|██████████| 44/44 [00:00<00:00, 89.50it/s]\n",
      "epoch 189 : lr 0.000100 : loss 0.146 : : 100%|██████████| 44/44 [00:00<00:00, 89.78it/s]\n",
      "epoch 190 : lr 0.000100 : loss 0.145 : : 100%|██████████| 44/44 [00:00<00:00, 90.47it/s]\n",
      "epoch 191 : lr 0.000100 : loss 0.144 : : 100%|██████████| 44/44 [00:00<00:00, 88.98it/s]\n",
      "epoch 192 : lr 0.000100 : loss 0.144 : : 100%|██████████| 44/44 [00:00<00:00, 88.91it/s]\n",
      "epoch 193 : lr 0.000100 : loss 0.143 : : 100%|██████████| 44/44 [00:00<00:00, 89.65it/s]\n",
      "epoch 194 : lr 0.000100 : loss 0.142 : : 100%|██████████| 44/44 [00:00<00:00, 89.52it/s]\n",
      "epoch 195 : lr 0.000100 : loss 0.142 : : 100%|██████████| 44/44 [00:00<00:00, 84.32it/s]\n",
      "epoch 196 : lr 0.000100 : loss 0.141 : : 100%|██████████| 44/44 [00:00<00:00, 90.30it/s]\n",
      "epoch 197 : lr 0.000100 : loss 0.140 : : 100%|██████████| 44/44 [00:00<00:00, 87.91it/s]\n",
      "epoch 198 : lr 0.000100 : loss 0.140 : : 100%|██████████| 44/44 [00:00<00:00, 86.84it/s]\n",
      "epoch 199 : lr 0.000100 : loss 0.139 : : 100%|██████████| 44/44 [00:00<00:00, 86.34it/s]\n",
      "WARNING:absl:Found untraced functions such as lambda_16_layer_call_and_return_conditional_losses, lambda_16_layer_call_fn, lambda_17_layer_call_and_return_conditional_losses, lambda_17_layer_call_fn, lambda_18_layer_call_and_return_conditional_losses while saving (showing 5 of 40). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lambda_16_layer_call_and_return_conditional_losses, lambda_16_layer_call_fn, lambda_17_layer_call_and_return_conditional_losses, lambda_17_layer_call_fn, lambda_18_layer_call_and_return_conditional_losses while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/models/gcn_model_Fiehn_HILIC/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/models/gcn_model_Fiehn_HILIC/assets\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "\n",
    "# Train on all data\n",
    "train_dataset = GCNDataset(\n",
    "    [f'../input/tfrecords/Fiehn_HILIC/train.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/valid.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/test_1.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/test_2.tfrec'], \n",
    "    batch_size, training=True)\n",
    "\n",
    "# build model (with default hyper-parameters)\n",
    "gcn_model_hilic = GCNModel()\n",
    "\n",
    "# fit model for {num_epochs} with a batch_size of {batch_size}\n",
    "gcn_model_hilic.fit(\n",
    "    train_dataset.get_iterator(), \n",
    "    epochs=num_epochs, verbose=1\n",
    ")\n",
    "\n",
    "# remcompile with vanilla gradient descent (SGD)\n",
    "gcn_model_hilic.compile(optimizer=tf.keras.optimizers.SGD())\n",
    "\n",
    "# CREATE DIR\n",
    "# save model\n",
    "tf.saved_model.save(gcn_model_hilic, f'../output/models/gcn_model_Fiehn_HILIC', serve_model(gcn_model_hilic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164d308cfc19466ab8a168dc210a4588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "saliency_hilic = saliency.Saliency(import_dir=f'../output/models/gcn_model_Fiehn_HILIC')\n",
    "\n",
    "# define new dataset (with training=False)\n",
    "dataset = GCNDataset(\n",
    "    [f'../input/tfrecords/Fiehn_HILIC/train.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/valid.tfrec', \n",
    "     f'../input/tfrecords/Fiehn_HILIC/test_1.tfrec',\n",
    "     f'../input/tfrecords/Fiehn_HILIC/test_2.tfrec'], \n",
    "    batch_size, training=False)\n",
    "\n",
    "# obtain dataset as a numpy iterator\n",
    "dataset = dataset.get_iterator()\n",
    "dataset = dataset.as_numpy_iterator()\n",
    "\n",
    "# loop over dataset in batches\n",
    "for batch in tqdm(dataset):\n",
    "    \n",
    "    # loop over each example in batch and compute its saliency map\n",
    "    # and finally save to file\n",
    "    for index in range(batch['label'].shape[0]):\n",
    "        A = batch['adjacency_matrix'][index]\n",
    "        H = batch['feature_matrix'][index]\n",
    "        y = batch['label'][index]\n",
    "        s = batch['string'][index][0]\n",
    "        i = batch['index'][index][0]\n",
    "        \n",
    "        saliency_map = saliency_hilic.atom_importance(A, H, y)\n",
    "        \n",
    "        # build RDKit mol object from string (SMILES)\n",
    "        mol = transform_ops.mol_from_string(s.decode('utf-8'))\n",
    "        \n",
    "        # draw saliency map on 2-d representation of mol object and save to file\n",
    "        saliency_hilic.draw_atom_saliency_on_mol(\n",
    "            mol, saliency_map, f'../output/saliency/test/mol_Fiehn_HILIC_{i}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train on RIKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 000 : lr 0.001000 : loss 1.508 : : 100%|██████████| 27/27 [00:01<00:00, 20.51it/s]\n",
      "epoch 001 : lr 0.001000 : loss 1.182 : : 100%|██████████| 27/27 [00:00<00:00, 82.47it/s]\n",
      "epoch 002 : lr 0.001000 : loss 0.975 : : 100%|██████████| 27/27 [00:00<00:00, 79.82it/s]\n",
      "epoch 003 : lr 0.001000 : loss 0.857 : : 100%|██████████| 27/27 [00:00<00:00, 81.23it/s]\n",
      "epoch 004 : lr 0.001000 : loss 0.794 : : 100%|██████████| 27/27 [00:00<00:00, 83.44it/s]\n",
      "epoch 005 : lr 0.001000 : loss 0.727 : : 100%|██████████| 27/27 [00:00<00:00, 80.36it/s]\n",
      "epoch 006 : lr 0.001000 : loss 0.678 : : 100%|██████████| 27/27 [00:00<00:00, 79.91it/s]\n",
      "epoch 007 : lr 0.001000 : loss 0.637 : : 100%|██████████| 27/27 [00:00<00:00, 80.44it/s]\n",
      "epoch 008 : lr 0.001000 : loss 0.601 : : 100%|██████████| 27/27 [00:00<00:00, 81.38it/s]\n",
      "epoch 009 : lr 0.001000 : loss 0.571 : : 100%|██████████| 27/27 [00:00<00:00, 79.42it/s]\n",
      "epoch 010 : lr 0.001000 : loss 0.545 : : 100%|██████████| 27/27 [00:00<00:00, 79.51it/s]\n",
      "epoch 011 : lr 0.001000 : loss 0.522 : : 100%|██████████| 27/27 [00:00<00:00, 81.48it/s]\n",
      "epoch 012 : lr 0.001000 : loss 0.503 : : 100%|██████████| 27/27 [00:00<00:00, 79.22it/s]\n",
      "epoch 013 : lr 0.001000 : loss 0.493 : : 100%|██████████| 27/27 [00:00<00:00, 79.52it/s]\n",
      "epoch 014 : lr 0.001000 : loss 0.482 : : 100%|██████████| 27/27 [00:00<00:00, 82.26it/s]\n",
      "epoch 015 : lr 0.001000 : loss 0.466 : : 100%|██████████| 27/27 [00:00<00:00, 81.58it/s]\n",
      "epoch 016 : lr 0.001000 : loss 0.451 : : 100%|██████████| 27/27 [00:00<00:00, 81.71it/s]\n",
      "epoch 017 : lr 0.001000 : loss 0.441 : : 100%|██████████| 27/27 [00:00<00:00, 81.96it/s]\n",
      "epoch 018 : lr 0.001000 : loss 0.431 : : 100%|██████████| 27/27 [00:00<00:00, 81.17it/s]\n",
      "epoch 019 : lr 0.001000 : loss 0.420 : : 100%|██████████| 27/27 [00:00<00:00, 81.44it/s]\n",
      "epoch 020 : lr 0.001000 : loss 0.411 : : 100%|██████████| 27/27 [00:00<00:00, 82.16it/s]\n",
      "epoch 021 : lr 0.001000 : loss 0.401 : : 100%|██████████| 27/27 [00:00<00:00, 79.01it/s]\n",
      "epoch 022 : lr 0.001000 : loss 0.394 : : 100%|██████████| 27/27 [00:00<00:00, 82.02it/s]\n",
      "epoch 023 : lr 0.001000 : loss 0.386 : : 100%|██████████| 27/27 [00:00<00:00, 79.84it/s]\n",
      "epoch 024 : lr 0.001000 : loss 0.379 : : 100%|██████████| 27/27 [00:00<00:00, 79.64it/s]\n",
      "epoch 025 : lr 0.001000 : loss 0.371 : : 100%|██████████| 27/27 [00:00<00:00, 82.28it/s]\n",
      "epoch 026 : lr 0.001000 : loss 0.364 : : 100%|██████████| 27/27 [00:00<00:00, 81.77it/s]\n",
      "epoch 027 : lr 0.001000 : loss 0.357 : : 100%|██████████| 27/27 [00:00<00:00, 82.18it/s]\n",
      "epoch 028 : lr 0.001000 : loss 0.351 : : 100%|██████████| 27/27 [00:00<00:00, 80.65it/s]\n",
      "epoch 029 : lr 0.001000 : loss 0.345 : : 100%|██████████| 27/27 [00:00<00:00, 79.64it/s]\n",
      "epoch 030 : lr 0.001000 : loss 0.340 : : 100%|██████████| 27/27 [00:00<00:00, 81.37it/s]\n",
      "epoch 031 : lr 0.001000 : loss 0.335 : : 100%|██████████| 27/27 [00:00<00:00, 82.09it/s]\n",
      "epoch 032 : lr 0.001000 : loss 0.329 : : 100%|██████████| 27/27 [00:00<00:00, 81.25it/s]\n",
      "epoch 033 : lr 0.001000 : loss 0.324 : : 100%|██████████| 27/27 [00:00<00:00, 82.61it/s]\n",
      "epoch 034 : lr 0.001000 : loss 0.320 : : 100%|██████████| 27/27 [00:00<00:00, 81.12it/s]\n",
      "epoch 035 : lr 0.001000 : loss 0.315 : : 100%|██████████| 27/27 [00:00<00:00, 82.46it/s]\n",
      "epoch 036 : lr 0.001000 : loss 0.311 : : 100%|██████████| 27/27 [00:00<00:00, 82.06it/s]\n",
      "epoch 037 : lr 0.001000 : loss 0.307 : : 100%|██████████| 27/27 [00:00<00:00, 83.02it/s]\n",
      "epoch 038 : lr 0.001000 : loss 0.303 : : 100%|██████████| 27/27 [00:00<00:00, 84.41it/s]\n",
      "epoch 039 : lr 0.001000 : loss 0.299 : : 100%|██████████| 27/27 [00:00<00:00, 82.11it/s]\n",
      "epoch 040 : lr 0.001000 : loss 0.295 : : 100%|██████████| 27/27 [00:00<00:00, 81.21it/s]\n",
      "epoch 041 : lr 0.001000 : loss 0.291 : : 100%|██████████| 27/27 [00:00<00:00, 81.64it/s]\n",
      "epoch 042 : lr 0.001000 : loss 0.288 : : 100%|██████████| 27/27 [00:00<00:00, 81.24it/s]\n",
      "epoch 043 : lr 0.001000 : loss 0.285 : : 100%|██████████| 27/27 [00:00<00:00, 82.56it/s]\n",
      "epoch 044 : lr 0.001000 : loss 0.281 : : 100%|██████████| 27/27 [00:00<00:00, 82.22it/s]\n",
      "epoch 045 : lr 0.001000 : loss 0.278 : : 100%|██████████| 27/27 [00:00<00:00, 80.08it/s]\n",
      "epoch 046 : lr 0.001000 : loss 0.275 : : 100%|██████████| 27/27 [00:00<00:00, 76.98it/s]\n",
      "epoch 047 : lr 0.001000 : loss 0.272 : : 100%|██████████| 27/27 [00:00<00:00, 83.15it/s]\n",
      "epoch 048 : lr 0.001000 : loss 0.271 : : 100%|██████████| 27/27 [00:00<00:00, 81.35it/s]\n",
      "epoch 049 : lr 0.001000 : loss 0.268 : : 100%|██████████| 27/27 [00:00<00:00, 82.32it/s]\n",
      "epoch 050 : lr 0.001000 : loss 0.266 : : 100%|██████████| 27/27 [00:00<00:00, 81.57it/s]\n",
      "epoch 051 : lr 0.001000 : loss 0.264 : : 100%|██████████| 27/27 [00:00<00:00, 81.16it/s]\n",
      "epoch 052 : lr 0.001000 : loss 0.261 : : 100%|██████████| 27/27 [00:00<00:00, 80.18it/s]\n",
      "epoch 053 : lr 0.001000 : loss 0.259 : : 100%|██████████| 27/27 [00:00<00:00, 79.07it/s]\n",
      "epoch 054 : lr 0.001000 : loss 0.257 : : 100%|██████████| 27/27 [00:00<00:00, 82.21it/s]\n",
      "epoch 055 : lr 0.001000 : loss 0.255 : : 100%|██████████| 27/27 [00:00<00:00, 77.81it/s]\n",
      "epoch 056 : lr 0.001000 : loss 0.253 : : 100%|██████████| 27/27 [00:00<00:00, 81.85it/s]\n",
      "epoch 057 : lr 0.001000 : loss 0.251 : : 100%|██████████| 27/27 [00:00<00:00, 80.52it/s]\n",
      "epoch 058 : lr 0.001000 : loss 0.249 : : 100%|██████████| 27/27 [00:00<00:00, 81.77it/s]\n",
      "epoch 059 : lr 0.001000 : loss 0.247 : : 100%|██████████| 27/27 [00:00<00:00, 80.23it/s]\n",
      "epoch 060 : lr 0.001000 : loss 0.245 : : 100%|██████████| 27/27 [00:00<00:00, 79.87it/s]\n",
      "epoch 061 : lr 0.001000 : loss 0.243 : : 100%|██████████| 27/27 [00:00<00:00, 78.12it/s]\n",
      "epoch 062 : lr 0.001000 : loss 0.241 : : 100%|██████████| 27/27 [00:00<00:00, 83.08it/s]\n",
      "epoch 063 : lr 0.001000 : loss 0.239 : : 100%|██████████| 27/27 [00:00<00:00, 82.50it/s]\n",
      "epoch 064 : lr 0.001000 : loss 0.237 : : 100%|██████████| 27/27 [00:00<00:00, 81.96it/s]\n",
      "epoch 065 : lr 0.001000 : loss 0.235 : : 100%|██████████| 27/27 [00:00<00:00, 82.74it/s]\n",
      "epoch 066 : lr 0.001000 : loss 0.234 : : 100%|██████████| 27/27 [00:00<00:00, 82.11it/s]\n",
      "epoch 067 : lr 0.001000 : loss 0.232 : : 100%|██████████| 27/27 [00:00<00:00, 81.45it/s]\n",
      "epoch 068 : lr 0.001000 : loss 0.231 : : 100%|██████████| 27/27 [00:00<00:00, 79.79it/s]\n",
      "epoch 069 : lr 0.001000 : loss 0.229 : : 100%|██████████| 27/27 [00:00<00:00, 82.31it/s]\n",
      "epoch 070 : lr 0.001000 : loss 0.227 : : 100%|██████████| 27/27 [00:00<00:00, 81.66it/s]\n",
      "epoch 071 : lr 0.001000 : loss 0.226 : : 100%|██████████| 27/27 [00:00<00:00, 81.97it/s]\n",
      "epoch 072 : lr 0.001000 : loss 0.225 : : 100%|██████████| 27/27 [00:00<00:00, 81.38it/s]\n",
      "epoch 073 : lr 0.001000 : loss 0.224 : : 100%|██████████| 27/27 [00:00<00:00, 82.88it/s]\n",
      "epoch 074 : lr 0.001000 : loss 0.222 : : 100%|██████████| 27/27 [00:00<00:00, 83.17it/s]\n",
      "epoch 075 : lr 0.001000 : loss 0.221 : : 100%|██████████| 27/27 [00:00<00:00, 81.79it/s]\n",
      "epoch 076 : lr 0.001000 : loss 0.219 : : 100%|██████████| 27/27 [00:00<00:00, 82.46it/s]\n",
      "epoch 077 : lr 0.001000 : loss 0.218 : : 100%|██████████| 27/27 [00:00<00:00, 80.98it/s]\n",
      "epoch 078 : lr 0.001000 : loss 0.217 : : 100%|██████████| 27/27 [00:00<00:00, 82.36it/s]\n",
      "epoch 079 : lr 0.001000 : loss 0.216 : : 100%|██████████| 27/27 [00:00<00:00, 82.85it/s]\n",
      "epoch 080 : lr 0.001000 : loss 0.214 : : 100%|██████████| 27/27 [00:00<00:00, 82.55it/s]\n",
      "epoch 081 : lr 0.001000 : loss 0.213 : : 100%|██████████| 27/27 [00:00<00:00, 79.71it/s]\n",
      "epoch 082 : lr 0.001000 : loss 0.212 : : 100%|██████████| 27/27 [00:00<00:00, 81.98it/s]\n",
      "epoch 083 : lr 0.001000 : loss 0.211 : : 100%|██████████| 27/27 [00:00<00:00, 82.67it/s]\n",
      "epoch 084 : lr 0.001000 : loss 0.210 : : 100%|██████████| 27/27 [00:00<00:00, 82.58it/s]\n",
      "epoch 085 : lr 0.001000 : loss 0.209 : : 100%|██████████| 27/27 [00:00<00:00, 78.51it/s]\n",
      "epoch 086 : lr 0.001000 : loss 0.208 : : 100%|██████████| 27/27 [00:00<00:00, 80.81it/s]\n",
      "epoch 087 : lr 0.001000 : loss 0.207 : : 100%|██████████| 27/27 [00:00<00:00, 80.29it/s]\n",
      "epoch 088 : lr 0.001000 : loss 0.205 : : 100%|██████████| 27/27 [00:00<00:00, 80.22it/s]\n",
      "epoch 089 : lr 0.001000 : loss 0.204 : : 100%|██████████| 27/27 [00:00<00:00, 79.99it/s]\n",
      "epoch 090 : lr 0.001000 : loss 0.203 : : 100%|██████████| 27/27 [00:00<00:00, 81.15it/s]\n",
      "epoch 091 : lr 0.001000 : loss 0.202 : : 100%|██████████| 27/27 [00:00<00:00, 82.85it/s]\n",
      "epoch 092 : lr 0.001000 : loss 0.201 : : 100%|██████████| 27/27 [00:00<00:00, 82.31it/s]\n",
      "epoch 093 : lr 0.001000 : loss 0.200 : : 100%|██████████| 27/27 [00:00<00:00, 80.92it/s]\n",
      "epoch 094 : lr 0.001000 : loss 0.199 : : 100%|██████████| 27/27 [00:00<00:00, 81.42it/s]\n",
      "epoch 095 : lr 0.001000 : loss 0.198 : : 100%|██████████| 27/27 [00:00<00:00, 81.12it/s]\n",
      "epoch 096 : lr 0.001000 : loss 0.197 : : 100%|██████████| 27/27 [00:00<00:00, 82.03it/s]\n",
      "epoch 097 : lr 0.001000 : loss 0.196 : : 100%|██████████| 27/27 [00:00<00:00, 81.74it/s]\n",
      "epoch 098 : lr 0.001000 : loss 0.195 : : 100%|██████████| 27/27 [00:00<00:00, 82.38it/s]\n",
      "epoch 099 : lr 0.001000 : loss 0.195 : : 100%|██████████| 27/27 [00:00<00:00, 83.14it/s]\n",
      "epoch 100 : lr 0.001000 : loss 0.194 : : 100%|██████████| 27/27 [00:00<00:00, 80.36it/s]\n",
      "epoch 101 : lr 0.001000 : loss 0.193 : : 100%|██████████| 27/27 [00:00<00:00, 78.89it/s]\n",
      "epoch 102 : lr 0.001000 : loss 0.192 : : 100%|██████████| 27/27 [00:00<00:00, 83.30it/s]\n",
      "epoch 103 : lr 0.001000 : loss 0.191 : : 100%|██████████| 27/27 [00:00<00:00, 82.44it/s]\n",
      "epoch 104 : lr 0.001000 : loss 0.190 : : 100%|██████████| 27/27 [00:00<00:00, 81.58it/s]\n",
      "epoch 105 : lr 0.001000 : loss 0.189 : : 100%|██████████| 27/27 [00:00<00:00, 80.87it/s]\n",
      "epoch 106 : lr 0.001000 : loss 0.188 : : 100%|██████████| 27/27 [00:00<00:00, 82.46it/s]\n",
      "epoch 107 : lr 0.001000 : loss 0.187 : : 100%|██████████| 27/27 [00:00<00:00, 78.52it/s]\n",
      "epoch 108 : lr 0.001000 : loss 0.186 : : 100%|██████████| 27/27 [00:00<00:00, 80.44it/s]\n",
      "epoch 109 : lr 0.001000 : loss 0.186 : : 100%|██████████| 27/27 [00:00<00:00, 80.15it/s]\n",
      "epoch 110 : lr 0.001000 : loss 0.185 : : 100%|██████████| 27/27 [00:00<00:00, 80.87it/s]\n",
      "epoch 111 : lr 0.001000 : loss 0.184 : : 100%|██████████| 27/27 [00:00<00:00, 82.06it/s]\n",
      "epoch 112 : lr 0.001000 : loss 0.183 : : 100%|██████████| 27/27 [00:00<00:00, 80.45it/s]\n",
      "epoch 113 : lr 0.001000 : loss 0.182 : : 100%|██████████| 27/27 [00:00<00:00, 81.33it/s]\n",
      "epoch 114 : lr 0.001000 : loss 0.181 : : 100%|██████████| 27/27 [00:00<00:00, 80.31it/s]\n",
      "epoch 115 : lr 0.001000 : loss 0.180 : : 100%|██████████| 27/27 [00:00<00:00, 82.82it/s]\n",
      "epoch 116 : lr 0.001000 : loss 0.180 : : 100%|██████████| 27/27 [00:00<00:00, 80.17it/s]\n",
      "epoch 117 : lr 0.001000 : loss 0.179 : : 100%|██████████| 27/27 [00:00<00:00, 82.14it/s]\n",
      "epoch 118 : lr 0.001000 : loss 0.178 : : 100%|██████████| 27/27 [00:00<00:00, 79.10it/s]\n",
      "epoch 119 : lr 0.001000 : loss 0.177 : : 100%|██████████| 27/27 [00:00<00:00, 82.60it/s]\n",
      "epoch 120 : lr 0.001000 : loss 0.177 : : 100%|██████████| 27/27 [00:00<00:00, 80.21it/s]\n",
      "epoch 121 : lr 0.001000 : loss 0.176 : : 100%|██████████| 27/27 [00:00<00:00, 81.93it/s]\n",
      "epoch 122 : lr 0.001000 : loss 0.176 : : 100%|██████████| 27/27 [00:00<00:00, 79.20it/s]\n",
      "epoch 123 : lr 0.001000 : loss 0.175 : : 100%|██████████| 27/27 [00:00<00:00, 81.72it/s]\n",
      "epoch 124 : lr 0.001000 : loss 0.174 : : 100%|██████████| 27/27 [00:00<00:00, 81.55it/s]\n",
      "epoch 125 : lr 0.001000 : loss 0.173 : : 100%|██████████| 27/27 [00:00<00:00, 79.89it/s]\n",
      "epoch 126 : lr 0.001000 : loss 0.173 : : 100%|██████████| 27/27 [00:00<00:00, 82.37it/s]\n",
      "epoch 127 : lr 0.001000 : loss 0.172 : : 100%|██████████| 27/27 [00:00<00:00, 76.92it/s]\n",
      "epoch 128 : lr 0.001000 : loss 0.171 : : 100%|██████████| 27/27 [00:00<00:00, 78.90it/s]\n",
      "epoch 129 : lr 0.001000 : loss 0.171 : : 100%|██████████| 27/27 [00:00<00:00, 78.57it/s]\n",
      "epoch 130 : lr 0.001000 : loss 0.170 : : 100%|██████████| 27/27 [00:00<00:00, 82.48it/s]\n",
      "epoch 131 : lr 0.001000 : loss 0.170 : : 100%|██████████| 27/27 [00:00<00:00, 79.03it/s]\n",
      "epoch 132 : lr 0.001000 : loss 0.169 : : 100%|██████████| 27/27 [00:00<00:00, 78.81it/s]\n",
      "epoch 133 : lr 0.001000 : loss 0.168 : : 100%|██████████| 27/27 [00:00<00:00, 77.11it/s]\n",
      "epoch 134 : lr 0.001000 : loss 0.168 : : 100%|██████████| 27/27 [00:00<00:00, 75.50it/s]\n",
      "epoch 135 : lr 0.001000 : loss 0.167 : : 100%|██████████| 27/27 [00:00<00:00, 79.52it/s]\n",
      "epoch 136 : lr 0.001000 : loss 0.167 : : 100%|██████████| 27/27 [00:00<00:00, 78.20it/s]\n",
      "epoch 137 : lr 0.001000 : loss 0.166 : : 100%|██████████| 27/27 [00:00<00:00, 84.46it/s]\n",
      "epoch 138 : lr 0.001000 : loss 0.165 : : 100%|██████████| 27/27 [00:00<00:00, 84.19it/s]\n",
      "epoch 139 : lr 0.001000 : loss 0.165 : : 100%|██████████| 27/27 [00:00<00:00, 84.95it/s]\n",
      "epoch 140 : lr 0.001000 : loss 0.164 : : 100%|██████████| 27/27 [00:00<00:00, 86.09it/s]\n",
      "epoch 141 : lr 0.001000 : loss 0.164 : : 100%|██████████| 27/27 [00:00<00:00, 84.18it/s]\n",
      "epoch 142 : lr 0.001000 : loss 0.163 : : 100%|██████████| 27/27 [00:00<00:00, 83.72it/s]\n",
      "epoch 143 : lr 0.001000 : loss 0.163 : : 100%|██████████| 27/27 [00:00<00:00, 83.65it/s]\n",
      "epoch 144 : lr 0.001000 : loss 0.162 : : 100%|██████████| 27/27 [00:00<00:00, 85.89it/s]\n",
      "epoch 145 : lr 0.001000 : loss 0.162 : : 100%|██████████| 27/27 [00:00<00:00, 85.77it/s]\n",
      "epoch 146 : lr 0.001000 : loss 0.162 : : 100%|██████████| 27/27 [00:00<00:00, 84.79it/s]\n",
      "epoch 147 : lr 0.001000 : loss 0.161 : : 100%|██████████| 27/27 [00:00<00:00, 85.12it/s]\n",
      "epoch 148 : lr 0.001000 : loss 0.161 : : 100%|██████████| 27/27 [00:00<00:00, 84.05it/s]\n",
      "epoch 149 : lr 0.001000 : loss 0.160 : : 100%|██████████| 27/27 [00:00<00:00, 83.11it/s]\n",
      "epoch 150 : lr 0.001000 : loss 0.159 : : 100%|██████████| 27/27 [00:00<00:00, 80.34it/s]\n",
      "epoch 151 : lr 0.001000 : loss 0.159 : : 100%|██████████| 27/27 [00:00<00:00, 80.58it/s]\n",
      "epoch 152 : lr 0.001000 : loss 0.158 : : 100%|██████████| 27/27 [00:00<00:00, 79.56it/s]\n",
      "epoch 153 : lr 0.001000 : loss 0.158 : : 100%|██████████| 27/27 [00:00<00:00, 76.92it/s]\n",
      "epoch 154 : lr 0.001000 : loss 0.157 : : 100%|██████████| 27/27 [00:00<00:00, 75.59it/s]\n",
      "epoch 155 : lr 0.001000 : loss 0.156 : : 100%|██████████| 27/27 [00:00<00:00, 76.40it/s]\n",
      "epoch 156 : lr 0.001000 : loss 0.156 : : 100%|██████████| 27/27 [00:00<00:00, 78.83it/s]\n",
      "epoch 157 : lr 0.001000 : loss 0.155 : : 100%|██████████| 27/27 [00:00<00:00, 80.10it/s]\n",
      "epoch 158 : lr 0.001000 : loss 0.155 : : 100%|██████████| 27/27 [00:00<00:00, 77.21it/s]\n",
      "epoch 159 : lr 0.001000 : loss 0.154 : : 100%|██████████| 27/27 [00:00<00:00, 78.79it/s]\n",
      "epoch 160 : lr 0.001000 : loss 0.154 : : 100%|██████████| 27/27 [00:00<00:00, 77.36it/s]\n",
      "epoch 161 : lr 0.000100 : loss 0.153 : : 100%|██████████| 27/27 [00:00<00:00, 82.79it/s]\n",
      "epoch 162 : lr 0.000100 : loss 0.153 : : 100%|██████████| 27/27 [00:00<00:00, 78.71it/s]\n",
      "epoch 163 : lr 0.000100 : loss 0.152 : : 100%|██████████| 27/27 [00:00<00:00, 81.92it/s]\n",
      "epoch 164 : lr 0.000100 : loss 0.152 : : 100%|██████████| 27/27 [00:00<00:00, 81.25it/s]\n",
      "epoch 165 : lr 0.000100 : loss 0.151 : : 100%|██████████| 27/27 [00:00<00:00, 76.86it/s]\n",
      "epoch 166 : lr 0.000100 : loss 0.150 : : 100%|██████████| 27/27 [00:00<00:00, 79.69it/s]\n",
      "epoch 167 : lr 0.000100 : loss 0.150 : : 100%|██████████| 27/27 [00:00<00:00, 81.04it/s]\n",
      "epoch 168 : lr 0.000100 : loss 0.149 : : 100%|██████████| 27/27 [00:00<00:00, 72.63it/s]\n",
      "epoch 169 : lr 0.000100 : loss 0.149 : : 100%|██████████| 27/27 [00:00<00:00, 82.59it/s]\n",
      "epoch 170 : lr 0.000100 : loss 0.148 : : 100%|██████████| 27/27 [00:00<00:00, 81.95it/s]\n",
      "epoch 171 : lr 0.000100 : loss 0.148 : : 100%|██████████| 27/27 [00:00<00:00, 80.01it/s]\n",
      "epoch 172 : lr 0.000100 : loss 0.147 : : 100%|██████████| 27/27 [00:00<00:00, 80.10it/s]\n",
      "epoch 173 : lr 0.000100 : loss 0.146 : : 100%|██████████| 27/27 [00:00<00:00, 82.04it/s]\n",
      "epoch 174 : lr 0.000100 : loss 0.146 : : 100%|██████████| 27/27 [00:00<00:00, 81.40it/s]\n",
      "epoch 175 : lr 0.000100 : loss 0.145 : : 100%|██████████| 27/27 [00:00<00:00, 82.42it/s]\n",
      "epoch 176 : lr 0.000100 : loss 0.145 : : 100%|██████████| 27/27 [00:00<00:00, 82.26it/s]\n",
      "epoch 177 : lr 0.000100 : loss 0.144 : : 100%|██████████| 27/27 [00:00<00:00, 79.54it/s]\n",
      "epoch 178 : lr 0.000100 : loss 0.144 : : 100%|██████████| 27/27 [00:00<00:00, 81.55it/s]\n",
      "epoch 179 : lr 0.000100 : loss 0.143 : : 100%|██████████| 27/27 [00:00<00:00, 82.49it/s]\n",
      "epoch 180 : lr 0.000100 : loss 0.143 : : 100%|██████████| 27/27 [00:00<00:00, 81.97it/s]\n",
      "epoch 181 : lr 0.000100 : loss 0.142 : : 100%|██████████| 27/27 [00:00<00:00, 80.68it/s]\n",
      "epoch 182 : lr 0.000100 : loss 0.142 : : 100%|██████████| 27/27 [00:00<00:00, 79.82it/s]\n",
      "epoch 183 : lr 0.000100 : loss 0.141 : : 100%|██████████| 27/27 [00:00<00:00, 80.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 184 : lr 0.000100 : loss 0.141 : : 100%|██████████| 27/27 [00:00<00:00, 80.38it/s]\n",
      "epoch 185 : lr 0.000100 : loss 0.140 : : 100%|██████████| 27/27 [00:00<00:00, 80.07it/s]\n",
      "epoch 186 : lr 0.000100 : loss 0.140 : : 100%|██████████| 27/27 [00:00<00:00, 79.00it/s]\n",
      "epoch 187 : lr 0.000100 : loss 0.139 : : 100%|██████████| 27/27 [00:00<00:00, 80.84it/s]\n",
      "epoch 188 : lr 0.000100 : loss 0.139 : : 100%|██████████| 27/27 [00:00<00:00, 81.11it/s]\n",
      "epoch 189 : lr 0.000100 : loss 0.138 : : 100%|██████████| 27/27 [00:00<00:00, 82.42it/s]\n",
      "epoch 190 : lr 0.000100 : loss 0.138 : : 100%|██████████| 27/27 [00:00<00:00, 79.95it/s]\n",
      "epoch 191 : lr 0.000100 : loss 0.137 : : 100%|██████████| 27/27 [00:00<00:00, 80.61it/s]\n",
      "epoch 192 : lr 0.000100 : loss 0.137 : : 100%|██████████| 27/27 [00:00<00:00, 80.33it/s]\n",
      "epoch 193 : lr 0.000100 : loss 0.136 : : 100%|██████████| 27/27 [00:00<00:00, 81.32it/s]\n",
      "epoch 194 : lr 0.000100 : loss 0.136 : : 100%|██████████| 27/27 [00:00<00:00, 80.45it/s]\n",
      "epoch 195 : lr 0.000100 : loss 0.136 : : 100%|██████████| 27/27 [00:00<00:00, 80.93it/s]\n",
      "epoch 196 : lr 0.000100 : loss 0.135 : : 100%|██████████| 27/27 [00:00<00:00, 81.05it/s]\n",
      "epoch 197 : lr 0.000100 : loss 0.135 : : 100%|██████████| 27/27 [00:00<00:00, 80.21it/s]\n",
      "epoch 198 : lr 0.000100 : loss 0.134 : : 100%|██████████| 27/27 [00:00<00:00, 81.22it/s]\n",
      "epoch 199 : lr 0.000100 : loss 0.134 : : 100%|██████████| 27/27 [00:00<00:00, 80.23it/s]\n",
      "WARNING:absl:Found untraced functions such as lambda_24_layer_call_and_return_conditional_losses, lambda_24_layer_call_fn, lambda_25_layer_call_and_return_conditional_losses, lambda_25_layer_call_fn, lambda_26_layer_call_and_return_conditional_losses while saving (showing 5 of 40). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lambda_24_layer_call_and_return_conditional_losses, lambda_24_layer_call_fn, lambda_25_layer_call_and_return_conditional_losses, lambda_25_layer_call_fn, lambda_26_layer_call_and_return_conditional_losses while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/models/test2/gcn_model_RIKEN/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../output/models/test2/gcn_model_RIKEN/assets\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "\n",
    "# Train on all data\n",
    "train_dataset = GCNDataset(\n",
    "    [f'../input/tfrecords/RIKEN/train.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/valid.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/test_1.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/test_2.tfrec'], \n",
    "    batch_size, training=True)\n",
    "\n",
    "# build model (with default hyper-parameters)\n",
    "gcn_model = GCNModel()\n",
    "\n",
    "# fit model for {num_epochs} with a batch_size of {batch_size}\n",
    "gcn_model.fit(\n",
    "    train_dataset.get_iterator(), \n",
    "    epochs=num_epochs, verbose=1\n",
    ")\n",
    "\n",
    "# remcompile with vanilla gradient descent (SGD)\n",
    "gcn_model.compile(optimizer=tf.keras.optimizers.SGD())\n",
    "\n",
    "# CREATE DIR\n",
    "# save model\n",
    "tf.saved_model.save(gcn_model, f'../output/models/test2/gcn_model_RIKEN', serve_model(gcn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc28f1df11ea42daaff22e80b8e5c66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "saliency_rplc = saliency.Saliency(import_dir=f'../output/models/gcn_model_RIKEN')\n",
    "\n",
    "# define new dataset (with training=False)\n",
    "dataset = GCNDataset(\n",
    "    [f'../input/tfrecords/RIKEN/train.tfrec', \n",
    "     f'../input/tfrecords/RIKEN/valid.tfrec', \n",
    "     f'../input/tfrecords/RIKEN/test_1.tfrec',\n",
    "     f'../input/tfrecords/RIKEN/test_2.tfrec'], \n",
    "    batch_size, training=False)\n",
    "\n",
    "# obtain dataset as a numpy iterator\n",
    "dataset = dataset.get_iterator()\n",
    "dataset = dataset.as_numpy_iterator()\n",
    "\n",
    "# loop over dataset in batches\n",
    "for batch in tqdm(dataset):\n",
    "    \n",
    "    # loop over each example in batch and compute its saliency map\n",
    "    # and finally save to file\n",
    "    for index in range(batch['label'].shape[0]):\n",
    "        A = batch['adjacency_matrix'][index]\n",
    "        H = batch['feature_matrix'][index]\n",
    "        y = batch['label'][index]\n",
    "        s = batch['string'][index][0]\n",
    "        i = batch['index'][index][0]\n",
    "        \n",
    "        saliency_map = saliency_rplc.atom_importance(A, H, y)\n",
    "        \n",
    "        # build RDKit mol object from string (SMILES)\n",
    "        mol = transform_ops.mol_from_string(s.decode('utf-8'))\n",
    "        \n",
    "        # draw saliency map on 2-d representation of mol object and save to file\n",
    "        saliency_rplc.draw_atom_saliency_on_mol(\n",
    "            mol, saliency_map, f'../output/saliency/test2/mol_RIKEN_{i}.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
